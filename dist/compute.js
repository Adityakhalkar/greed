"use strict";(this.webpackChunkGreed=this.webpackChunkGreed||[]).push([[694],{228:(e,t,r)=>{r.d(t,{nn:()=>s});var i=r(847);class n{constructor(e){this.computeEngine=e,this.tensorRegistry=new Map,this.nextTensorId=0}createWebGPUTensor(e,t,r="float32",n="webgpu"){const a=new i.O(e,{shape:t,dtype:r,device:n,computeEngine:this.computeEngine}),s="webgpu_tensor_"+this.nextTensorId++;return this.tensorRegistry.set(s,a),{id:s,tensor:a,shape:a.shape,dtype:a.dtype,device:a.device}}getTensor(e){return this.tensorRegistry.get(e)}async executeCreationOperation(e,t={}){try{const{shape:r,size:n,device:a="webgpu",dtype:s="float32"}=t;if(!n&&!r)throw new Error("Either size or shape must be provided for tensor creation");const o=n||r.reduce((e,t)=>e*t,1),u=r||[n],p=await this.computeEngine.execute(e,[],{outputSize:o,dataType:"int64"===s?"i32":"f32",...t}),l=new i.O(p,{shape:u,dtype:s,device:a,computeEngine:this.computeEngine}),d="webgpu_tensor_"+this.nextTensorId++;return this.tensorRegistry.set(d,l),d}catch(e){return{success:!1,error:e.message}}}async executeBinaryOperation(e,t,r,n={}){const a=this.tensorRegistry.get(e),s=this.tensorRegistry.get(t);if(!a||!s)throw new Error(`Tensor not found: ${a?t:e}`);try{const e=await this.computeEngine.execute(r,[a,s],n),t=new i.O(e,{shape:a.shape,dtype:a.dtype,device:a.device,computeEngine:this.computeEngine}),o="webgpu_tensor_"+this.nextTensorId++;return this.tensorRegistry.set(o,t),{success:!0,id:o,data:Array.from(e),shape:t.shape,dtype:t.dtype}}catch(e){return{success:!1,error:e.message}}}async executeUnaryOperation(e,t,r={}){const n=this.tensorRegistry.get(e);if(!n)throw new Error(`Tensor ${e} not found`);try{const e=await this.computeEngine.execute(t,[n],r),a=new i.O(e,{shape:n.shape,dtype:n.dtype,device:n.device,computeEngine:this.computeEngine}),s="webgpu_tensor_"+this.nextTensorId++;return this.tensorRegistry.set(s,a),{success:!0,id:s,data:Array.from(e),shape:a.shape,dtype:a.dtype}}catch(e){return{success:!1,error:e.message}}}async executeOperation(e,t,r=null,i={}){const n=this.tensorRegistry.get(t);if(!n)throw new Error(`Tensor ${t} not found`);let a=null;if(r&&(a=this.tensorRegistry.get(r),!a))throw new Error(`Tensor ${r} not found`);try{let t;switch(e){case"add":t=await n.add(a);break;case"sub":t=await n.sub(a);break;case"mul":t=await n.mul(a);break;case"div":t=await n.div(a);break;case"matmul":t=await n.matmul(a);break;case"relu":t=await n.relu();break;case"sigmoid":t=await n.sigmoid();break;case"tanh":t=await n.tanh();break;case"softmax":t=await n.softmax(i.dim);break;case"sum":t=await n.sum(i.dim,i.keepdim);break;case"mean":t=await n.mean(i.dim,i.keepdim);break;case"transpose":t=await n.transpose(i.dim0,i.dim1);break;case"squeeze":t=await n.squeeze(i.dim);break;case"unsqueeze":t=await n.unsqueeze(i.dim);break;case"reshape":t=await n.reshape(i.shape);break;case"std":t=await n.std(i.dim,i.keepdim,i.unbiased);break;case"var":t=await n.var(i.dim,i.keepdim,i.unbiased);break;case"linear":const r=i.bias_id,s=r?this.tensorRegistry.get(r):null;t=await this.computeEngine.executeLinear(n,a,s,i);break;case"cross_entropy":t=await this.computeEngine.executeCrossEntropy(n,a,i);break;default:throw new Error(`Unsupported operation: ${e}`)}return this.createWebGPUTensor(t.data,t.shape,t.dtype,t.device).id}catch(e){return{success:!1,error:e.message}}}getTensorData(e){const t=this.tensorRegistry.get(e);if(!t)throw new Error(`Tensor ${e} not found`);return Array.from(t.data)}tensorToArray(e){const t=this.tensorRegistry.get(e);if(!t)throw new Error(`Tensor ${e} not found`);return{data:Array.from(t.data),shape:t.shape,dtype:t.dtype}}executeBackward(e,t){return console.log(`Executing backward pass for tensor ${e} with gradient ${t}`),!0}releaseTensor(e){return this.tensorRegistry.delete(e)}getStats(){return{tensorCount:this.tensorRegistry.size,totalMemory:Array.from(this.tensorRegistry.values()).reduce((e,t)=>e+4*t.size,0),deviceDistribution:this._getDeviceDistribution()}}cleanup(){this.tensorRegistry.clear(),this.nextTensorId=0}_getDeviceDistribution(){const e={};for(const t of this.tensorRegistry.values())e[t.device]=(e[t.device]||0)+1;return e}}let a=null;function s(e){return a=new n(e),"undefined"!=typeof window?window.greedTensorBridge=a:void 0!==r.g&&(r.g.greedTensorBridge=a),a}},493:(e,t,r)=>{r.d(t,{A:()=>w});var i=r(123);class n extends i.A{constructor(e,t={}){super(),this.device=e,this.config={maxPoolSize:t.maxPoolSize||100,maxBufferSize:t.maxBufferSize||268435456,gcThreshold:t.gcThreshold||.8,enablePooling:!1!==t.enablePooling,...t},this.pools=new Map,this.activeBuffers=new Map,this.totalMemoryUsage=0,this.peakMemoryUsage=0,this.stats={allocations:0,poolHits:0,poolMisses:0,releases:0,destroyed:0,currentActive:0,totalPooled:0}}allocate(e,t=GPUBufferUsage.STORAGE|GPUBufferUsage.COPY_SRC|GPUBufferUsage.COPY_DST){this._validateAllocation(e,t);const r=this._getPoolKey(e,t);let i=null;this.config.enablePooling&&(i=this._getFromPool(r),i&&(this.stats.poolHits++,this.emit("buffer:reused",{size:e,usage:t,poolKey:r}))),i||(i=this.device.createBuffer({size:e,usage:t}),this.stats.poolMisses++,this.emit("buffer:created",{size:e,usage:t,poolKey:r}));const n={size:e,usage:t,poolKey:r,allocatedAt:performance.now(),lastAccessed:performance.now()};return this.activeBuffers.set(i,n),this.totalMemoryUsage+=e,this.peakMemoryUsage=Math.max(this.peakMemoryUsage,this.totalMemoryUsage),this.stats.allocations++,this.stats.currentActive=this.activeBuffers.size,this.emit("buffer:allocated",{buffer:i,metadata:n}),this._checkMemoryPressure(),i}release(e,t={}){const{forceDestroy:r=!1}=t,i=this.activeBuffers.get(e);return i?(this.activeBuffers.delete(e),this.totalMemoryUsage-=i.size,this.stats.releases++,this.stats.currentActive=this.activeBuffers.size,r||!this.config.enablePooling||this._shouldDestroyBuffer(e,i)?(this._destroyBuffer(e,i),!0):(this._addToPool(e,i)?this.emit("buffer:pooled",{buffer:e,poolKey:i.poolKey}):this._destroyBuffer(e,i),!0)):(this.emit("buffer:release-error",{error:"Buffer not found in active buffers"}),!1)}releaseAll(e,t={}){const r=[];for(const i of e)r.push(this.release(i,t));return r}async createMappedBuffer(e,t=GPUBufferUsage.COPY_SRC){const r=this._calculateBufferSize(e),i=this.allocate(r,t|GPUBufferUsage.MAP_WRITE);try{await i.mapAsync(GPUMapMode.WRITE);const t=i.getMappedRange();if(e instanceof ArrayBuffer)new Uint8Array(t).set(new Uint8Array(e));else{if(!ArrayBuffer.isView(e))throw new Error("Unsupported data type for mapped buffer");new Uint8Array(t).set(new Uint8Array(e.buffer,e.byteOffset,e.byteLength))}return i.unmap(),this.emit("buffer:mapped",{buffer:i,size:r,dataType:e.constructor.name}),i}catch(e){throw this.release(i,{forceDestroy:!0}),e}}copyBuffer(e,t,r,i={}){const{sourceOffset:n=0,destinationOffset:a=0,commandEncoder:s=null}=i;if(!this.activeBuffers.has(e)||!this.activeBuffers.has(t))throw new Error("Source or destination buffer not managed by this BufferManager");const o=s||this.device.createCommandEncoder();if(o.copyBufferToBuffer(e,n,t,a,r),!s){const e=o.finish();this.device.queue.submit([e])}this.emit("buffer:copied",{source:e,destination:t,size:r})}getStats(){return{...this.stats,totalMemoryUsageMB:Math.round(this.totalMemoryUsage/1048576*100)/100,peakMemoryUsageMB:Math.round(this.peakMemoryUsage/1048576*100)/100,poolCount:this.pools.size,totalPooled:Array.from(this.pools.values()).reduce((e,t)=>e+t.length,0),poolEfficiency:this.stats.allocations>0?this.stats.poolHits/this.stats.allocations:0}}async gc(e={}){const{aggressive:t=!1,maxAge:r=6e4,targetReduction:i=.5}=e;this.emit("gc:start",{aggressive:t,maxAge:r,targetReduction:i});let n=0;const a=performance.now(),s=this._getTotalPooledBuffers();for(const[e,o]of this.pools.entries()){const u=o.slice();for(let e=u.length-1;e>=0;e--){const p=u[e];if((t||p._pooledAt&&a-p._pooledAt>r)&&(o.splice(e,1),p.destroy(),n++,this.stats.destroyed++),n/s>=i)break}0===o.length&&this.pools.delete(e)}return this.emit("gc:complete",{destroyed:n,remaining:this._getTotalPooledBuffers()}),n}async emergencyCleanup(){this.emit("emergency:start");try{let e=0;for(const[t,r]of this.pools.entries())for(;r.length>0;){const t=r.pop();try{t.destroy(),e++,this.stats.destroyed++}catch(e){this.emit("buffer:destroy-error",{buffer:t,error:e})}}return this.pools.clear(),window.gc&&window.gc(),this.emit("emergency:complete",{destroyed:e}),e}catch(e){throw this.emit("emergency:error",{error:e}),e}}async cleanup(){this.emit("cleanup:start");try{for(const[e,t]of this.activeBuffers.entries())this._destroyBuffer(e,t);this.activeBuffers.clear();for(const e of this.pools.values())for(const t of e)t.destroy();this.pools.clear(),this.totalMemoryUsage=0,this.stats.currentActive=0,this.stats.totalPooled=0,this.emit("cleanup:complete")}catch(e){throw this.emit("cleanup:error",{error:e}),e}}_validateAllocation(e,t){if(e<=0||e>this.config.maxBufferSize)throw new Error(`Invalid buffer size: ${e}. Must be between 1 and ${this.config.maxBufferSize}`);if("number"!=typeof t)throw new Error("Buffer usage must be a number")}_getPoolKey(e,t){return`${e}-${t}`}_getFromPool(e){const t=this.pools.get(e);return t&&t.length>0?t.pop():null}_addToPool(e,t){const r=t.poolKey;this.pools.has(r)||this.pools.set(r,[]);const i=this.pools.get(r);return!(i.length>=this.config.maxPoolSize||(e._pooledAt=performance.now(),i.push(e),this.stats.totalPooled++,0))}_destroyBuffer(e,t){try{e.destroy(),this.stats.destroyed++,this.emit("buffer:destroyed",{buffer:e,metadata:t})}catch(t){this.emit("buffer:destroy-error",{buffer:e,error:t})}}_shouldDestroyBuffer(e,t){return t.size>this.config.maxBufferSize/4}_shouldRunGC(){return this.totalMemoryUsage/this.config.maxBufferSize>this.config.gcThreshold}async _runGC(){try{await this.gc({aggressive:!1})}catch(e){this.emit("gc:error",{error:e})}}_calculateBufferSize(e){if(e instanceof ArrayBuffer)return e.byteLength;if(ArrayBuffer.isView(e))return e.byteLength;if(Array.isArray(e))return 4*e.length;throw new Error("Cannot calculate buffer size for data type")}_getTotalPooledBuffers(){return Array.from(this.pools.values()).reduce((e,t)=>e+t.length,0)}_checkMemoryPressure(){const e=this.totalMemoryUsage/this.config.maxBufferSize;e>=.95?(this.emit("memory:critical",{memoryRatio:e,totalUsage:this.totalMemoryUsage,maxSize:this.config.maxBufferSize}),setTimeout(()=>this.emergencyCleanup(),0)):e>=this.config.gcThreshold?(this.emit("memory:pressure",{memoryRatio:e,totalUsage:this.totalMemoryUsage,maxSize:this.config.maxBufferSize}),setTimeout(()=>this.forceGC(),0)):e>=.6&&(this.emit("memory:warning",{memoryRatio:e,totalUsage:this.totalMemoryUsage,maxSize:this.config.maxBufferSize}),setTimeout(()=>this._runGC(),0))}_runGC(){const e=this._getTotalPooledBuffers();if(e>0){const t=Math.ceil(.2*e);let r=0;for(const[e,i]of this.pools.entries()){for(;i.length>0&&r<t;){const e=i.shift();try{e.destroy(),r++,this.stats.destroyed++}catch(t){this.emit("buffer:destroy-error",{buffer:e,error:t})}}if(0===i.length&&this.pools.delete(e),r>=t)break}this.emit("gc:automatic",{destroyed:r,remaining:this._getTotalPooledBuffers()})}}}const a=n;class s{static getShaderTemplates(){return new Map([["add",e=>`\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<${e.dataType}>;\n        @group(0) @binding(3) var<uniform> params: array<u32, 4>;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params[0];\n          if (index >= size) { return; }\n          output[index] = input1[index] + input2[index];\n        }\n      `],["sub",e=>`\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<${e.dataType}>;\n        @group(0) @binding(3) var<uniform> params: array<u32, 4>;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params[0];\n          if (index >= size) { return; }\n          output[index] = input1[index] - input2[index];\n        }\n      `],["mul",e=>`\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<${e.dataType}>;\n        @group(0) @binding(3) var<uniform> params: array<u32, 4>;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params[0];\n          if (index >= size) { return; }\n          output[index] = input1[index] * input2[index];\n        }\n      `],["div",e=>`\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<${e.dataType}>;\n        @group(0) @binding(3) var<uniform> params: array<u32, 4>;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params[0];\n          if (index >= size) { return; }\n          output[index] = input1[index] / input2[index];\n        }\n      `],["pow",e=>`\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<${e.dataType}>;\n        @group(0) @binding(3) var<uniform> params: array<u32, 4>;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params[0];\n          if (index >= size) { return; }\n          output[index] = pow(input1[index], input2[index]);\n        }\n      `],["matmul",e=>`\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<${e.dataType}>;\n        @group(0) @binding(3) var<uniform> params: array<u32, 4>;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let row = global_id.x;\n          let col = global_id.y;\n          let M = params[0];  // rows of A\n          let N = params[1];  // cols of B\n          let K = params[2];  // cols of A, rows of B\n          \n          if (row >= M || col >= N) { return; }\n          \n          var sum = 0.0;\n          for (var k = 0u; k < K; k = k + 1u) {\n            sum = sum + input1[row * K + k] * input2[k * N + col];\n          }\n          output[row * N + col] = sum;\n        }\n      `],["bmm",e=>`\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<${e.dataType}>;\n        @group(0) @binding(3) var<uniform> params: array<u32, 4>;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let batch = global_id.z;\n          let row = global_id.x;\n          let col = global_id.y;\n          \n          let B = params[0];  // batch size\n          let M = params[1];  // rows\n          let N = params[2];  // cols of second matrix\n          let K = params[3];  // cols of first matrix\n          \n          if (batch >= B || row >= M || col >= N) { return; }\n          \n          let batch_offset1 = batch * M * K;\n          let batch_offset2 = batch * K * N;\n          let batch_offset_out = batch * M * N;\n          \n          var sum = 0.0;\n          for (var k = 0u; k < K; k = k + 1u) {\n            sum = sum + input1[batch_offset1 + row * K + k] * input2[batch_offset2 + k * N + col];\n          }\n          output[batch_offset_out + row * N + col] = sum;\n        }\n      `],["transpose",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        @group(0) @binding(2) var<uniform> params: array<u32, 4>;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let rows = params[0];\n          let cols = params[1];\n          let size = rows * cols;\n          \n          if (index >= size) { return; }\n          \n          let row = index / cols;\n          let col = index % cols;\n          let transposed_index = col * rows + row;\n          \n          output[transposed_index] = input[index];\n        }\n      `],["relu",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        @group(0) @binding(2) var<uniform> params: array<u32, 4>;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params[0];\n          if (index >= size) { return; }\n          output[index] = max(input[index], 0.0);\n        }\n      `],["leaky_relu",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        @group(0) @binding(2) var<uniform> params: array<u32, 4>;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params[0];\n          let negative_slope = bitcast<f32>(params[1]);\n          if (index >= size) { return; }\n          let val = input[index];\n          output[index] = select(negative_slope * val, val, val > 0.0);\n        }\n      `],["sigmoid",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        @group(0) @binding(2) var<uniform> params: array<u32, 4>;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params[0];\n          if (index >= size) { return; }\n          output[index] = 1.0 / (1.0 + exp(-input[index]));\n        }\n      `],["tanh",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        @group(0) @binding(2) var<uniform> params: array<u32, 4>;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params[0];\n          if (index >= size) { return; }\n          output[index] = tanh(input[index]);\n        }\n      `],["gelu",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        @group(0) @binding(2) var<uniform> params: array<u32, 4>;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params[0];\n          if (index >= size) { return; }\n          let x = input[index];\n          // GELU approximation: 0.5 * x * (1 + tanh(sqrt(2/Ï€) * (x + 0.044715 * x^3)))\n          let sqrt_2_over_pi = 0.7978845608;\n          let inner = sqrt_2_over_pi * (x + 0.044715 * x * x * x);\n          output[index] = 0.5 * x * (1.0 + tanh(inner));\n        }\n      `],["softmax",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        @group(0) @binding(2) var<uniform> params: array<u32, 4>;\n\n        var<workgroup> shared_max: f32;\n        var<workgroup> shared_sum: f32;\n\n        @compute @workgroup_size(${Math.min(e.workgroupSize[0],256)})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>,\n                @builtin(local_invocation_id) local_id: vec3<u32>,\n                @builtin(workgroup_id) workgroup_id: vec3<u32>) {\n          let batch_size = params[0];\n          let dim_size = params[1];\n          let batch_idx = workgroup_id.x;\n          let local_idx = local_id.x;\n          \n          if (batch_idx >= batch_size) { return; }\n          \n          let batch_offset = batch_idx * dim_size;\n          \n          // Find maximum for numerical stability\n          var max_val = -3.4028235e+38; // -FLT_MAX\n          for (var i = local_idx; i < dim_size; i = i + ${Math.min(e.workgroupSize[0],256)}u) {\n            max_val = max(max_val, input[batch_offset + i]);\n          }\n          \n          // Reduce maximum across workgroup\n          workgroupBarrier();\n          if (local_idx == 0u) {\n            shared_max = max_val;\n          }\n          for (var stride = 1u; stride < ${Math.min(e.workgroupSize[0],256)}u; stride = stride * 2u) {\n            workgroupBarrier();\n            if (local_idx >= stride) {\n              shared_max = max(shared_max, max_val);\n            }\n          }\n          workgroupBarrier();\n          \n          // Compute exponentials and sum\n          var sum = 0.0;\n          for (var i = local_idx; i < dim_size; i = i + ${Math.min(e.workgroupSize[0],256)}u) {\n            let exp_val = exp(input[batch_offset + i] - shared_max);\n            sum = sum + exp_val;\n            output[batch_offset + i] = exp_val;\n          }\n          \n          // Reduce sum across workgroup\n          workgroupBarrier();\n          if (local_idx == 0u) {\n            shared_sum = sum;\n          }\n          for (var stride = 1u; stride < ${Math.min(e.workgroupSize[0],256)}u; stride = stride * 2u) {\n            workgroupBarrier();\n            if (local_idx >= stride) {\n              shared_sum = shared_sum + sum;\n            }\n          }\n          workgroupBarrier();\n          \n          // Normalize\n          for (var i = local_idx; i < dim_size; i = i + ${Math.min(e.workgroupSize[0],256)}u) {\n            output[batch_offset + i] = output[batch_offset + i] / shared_sum;\n          }\n        }\n      `],["sum",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        @group(0) @binding(2) var<uniform> params: array<u32, 4>;\n\n        var<workgroup> shared_data: array<f32, ${e.workgroupSize[0]}>;\n\n        @compute @workgroup_size(${e.workgroupSize[0]})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>,\n                @builtin(local_invocation_id) local_id: vec3<u32>,\n                @builtin(workgroup_id) workgroup_id: vec3<u32>) {\n          let size = params[0];\n          let local_idx = local_id.x;\n          let global_idx = global_id.x;\n          \n          // Load data into shared memory\n          var sum = 0.0;\n          for (var i = global_idx; i < size; i = i + ${e.workgroupSize[0]}u) {\n            sum = sum + input[i];\n          }\n          shared_data[local_idx] = sum;\n          \n          workgroupBarrier();\n          \n          // Parallel reduction\n          for (var stride = ${e.workgroupSize[0]/2}u; stride > 0u; stride = stride >> 1u) {\n            if (local_idx < stride) {\n              shared_data[local_idx] = shared_data[local_idx] + shared_data[local_idx + stride];\n            }\n            workgroupBarrier();\n          }\n          \n          if (local_idx == 0u) {\n            output[workgroup_id.x] = shared_data[0];\n          }\n        }\n      `],["mean",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        @group(0) @binding(2) var<uniform> params: array<u32, 4>;\n\n        var<workgroup> shared_data: array<f32, ${e.workgroupSize[0]}>;\n\n        @compute @workgroup_size(${e.workgroupSize[0]})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>,\n                @builtin(local_invocation_id) local_id: vec3<u32>,\n                @builtin(workgroup_id) workgroup_id: vec3<u32>) {\n          let size = params[0];\n          let local_idx = local_id.x;\n          let global_idx = global_id.x;\n          \n          var sum = 0.0;\n          for (var i = global_idx; i < size; i = i + ${e.workgroupSize[0]}u) {\n            sum = sum + input[i];\n          }\n          shared_data[local_idx] = sum;\n          \n          workgroupBarrier();\n          \n          for (var stride = ${e.workgroupSize[0]/2}u; stride > 0u; stride = stride >> 1u) {\n            if (local_idx < stride) {\n              shared_data[local_idx] = shared_data[local_idx] + shared_data[local_idx + stride];\n            }\n            workgroupBarrier();\n          }\n          \n          if (local_idx == 0u) {\n            output[workgroup_id.x] = shared_data[0] / f32(size);\n          }\n        }\n      `],["conv2d",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> weight: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read> bias: array<${e.dataType}>;\n        @group(0) @binding(3) var<storage, read_write> output: array<${e.dataType}>;\n        @group(0) @binding(4) var<uniform> params: array<u32, 8>;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let out_y = global_id.x;\n          let out_x = global_id.y;\n          let out_c = global_id.z;\n          \n          let batch_size = params[0];\n          let in_channels = params[1];\n          let in_height = params[2];\n          let in_width = params[3];\n          let out_channels = params[4];\n          let out_height = params[5];\n          let out_width = params[6];\n          let kernel_size = params[7];\n          \n          if (out_y >= out_height || out_x >= out_width || out_c >= out_channels) { return; }\n          \n          var sum = 0.0;\n          \n          for (var in_c = 0u; in_c < in_channels; in_c = in_c + 1u) {\n            for (var ky = 0u; ky < kernel_size; ky = ky + 1u) {\n              for (var kx = 0u; kx < kernel_size; kx = kx + 1u) {\n                let in_y = out_y + ky;\n                let in_x = out_x + kx;\n                \n                if (in_y < in_height && in_x < in_width) {\n                  let input_idx = in_c * in_height * in_width + in_y * in_width + in_x;\n                  let weight_idx = out_c * in_channels * kernel_size * kernel_size + \n                                  in_c * kernel_size * kernel_size + ky * kernel_size + kx;\n                  sum = sum + input[input_idx] * weight[weight_idx];\n                }\n              }\n            }\n          }\n          \n          sum = sum + bias[out_c];\n          let output_idx = out_c * out_height * out_width + out_y * out_width + out_x;\n          output[output_idx] = sum;\n        }\n      `],["maxpool2d",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        @group(0) @binding(2) var<uniform> params: array<u32, 8>;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let out_y = global_id.x;\n          let out_x = global_id.y;\n          let c = global_id.z;\n          \n          let channels = params[0];\n          let in_height = params[1];\n          let in_width = params[2];\n          let out_height = params[3];\n          let out_width = params[4];\n          let kernel_size = params[5];\n          let stride = params[6];\n          \n          if (out_y >= out_height || out_x >= out_width || c >= channels) { return; }\n          \n          var max_val = -3.4028235e+38; // -FLT_MAX\n          \n          for (var ky = 0u; ky < kernel_size; ky = ky + 1u) {\n            for (var kx = 0u; kx < kernel_size; kx = kx + 1u) {\n              let in_y = out_y * stride + ky;\n              let in_x = out_x * stride + kx;\n              \n              if (in_y < in_height && in_x < in_width) {\n                let input_idx = c * in_height * in_width + in_y * in_width + in_x;\n                max_val = max(max_val, input[input_idx]);\n              }\n            }\n          }\n          \n          let output_idx = c * out_height * out_width + out_y * out_width + out_x;\n          output[output_idx] = max_val;\n        }\n      `],["exp",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        @group(0) @binding(2) var<uniform> params: array<u32, 4>;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params[0];\n          if (index >= size) { return; }\n          output[index] = exp(input[index]);\n        }\n      `],["log",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        @group(0) @binding(2) var<uniform> params: array<u32, 4>;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params[0];\n          if (index >= size) { return; }\n          output[index] = log(input[index]);\n        }\n      `],["sqrt",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        @group(0) @binding(2) var<uniform> params: array<u32, 4>;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params[0];\n          if (index >= size) { return; }\n          output[index] = sqrt(input[index]);\n        }\n      `],["abs",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        @group(0) @binding(2) var<uniform> params: array<u32, 4>;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params[0];\n          if (index >= size) { return; }\n          output[index] = abs(input[index]);\n        }\n      `],["max",e=>`\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<${e.dataType}>;\n        @group(0) @binding(3) var<uniform> params: array<u32, 4>;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params[0];\n          if (index >= size) { return; }\n          output[index] = max(input1[index], input2[index]);\n        }\n      `],["min",e=>`\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<${e.dataType}>;\n        @group(0) @binding(3) var<uniform> params: array<u32, 4>;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params[0];\n          if (index >= size) { return; }\n          output[index] = min(input1[index], input2[index]);\n        }\n      `],["concat",e=>`\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<${e.dataType}>;\n        @group(0) @binding(3) var<uniform> params: array<u32, 4>;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size1 = params[0];\n          let size2 = params[1];\n          let total_size = size1 + size2;\n          \n          if (index >= total_size) { return; }\n          \n          if (index < size1) {\n            output[index] = input1[index];\n          } else {\n            output[index] = input2[index - size1];\n          }\n        }\n      `],["slice",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        @group(0) @binding(2) var<uniform> params: array<u32, 4>;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let start = params[0];\n          let end = params[1];\n          let step = params[2];\n          let output_size = (end - start + step - 1u) / step;\n          \n          if (index >= output_size) { return; }\n          \n          let input_index = start + index * step;\n          output[index] = input[input_index];\n        }\n      `],["batch_norm",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> running_mean: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read> running_var: array<${e.dataType}>;\n        @group(0) @binding(3) var<storage, read> weight: array<${e.dataType}>;\n        @group(0) @binding(4) var<storage, read> bias: array<${e.dataType}>;\n        @group(0) @binding(5) var<storage, read_write> output: array<${e.dataType}>;\n        @group(0) @binding(6) var<uniform> params: array<u32, 4>;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let batch_size = params[0];\n          let channels = params[1];\n          let spatial_size = params[2];\n          let eps = bitcast<f32>(params[3]);\n          \n          if (index >= batch_size * channels * spatial_size) { return; }\n          \n          let c = (index / spatial_size) % channels;\n          let normalized = (input[index] - running_mean[c]) / sqrt(running_var[c] + eps);\n          output[index] = normalized * weight[c] + bias[c];\n        }\n      `],["rand",e=>`\n        @group(0) @binding(0) var<storage, read_write> output: array<${e.dataType}>;\n        @group(0) @binding(1) var<uniform> params: array<u32, 4>;\n\n        // Linear Congruential Generator for pseudo-random numbers\n        fn random_lcg(seed: u32) -> f32 {\n          let a = 1664525u;\n          let c = 1013904223u;\n          let m = 0xFFFFFFFFu;\n          let next_seed = (a * seed + c) % m;\n          return f32(next_seed) / f32(m);\n        }\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params[0];\n          let seed_base = params[1];\n          \n          if (index >= size) { return; }\n          \n          // Generate unique seed for each thread\n          let seed = seed_base + index * 747796405u + global_id.y * 2891336453u;\n          output[index] = random_lcg(seed);\n        }\n      `],["randn",e=>`\n        @group(0) @binding(0) var<storage, read_write> output: array<${e.dataType}>;\n        @group(0) @binding(1) var<uniform> params: array<u32, 4>;\n\n        // Box-Muller transform for normal distribution\n        fn random_normal(seed1: u32, seed2: u32) -> vec2<f32> {\n          let a = 1664525u;\n          let c = 1013904223u;\n          let m = 0xFFFFFFFFu;\n          \n          let next_seed1 = (a * seed1 + c) % m;\n          let next_seed2 = (a * seed2 + c) % m;\n          \n          let u1 = f32(next_seed1) / f32(m);\n          let u2 = f32(next_seed2) / f32(m);\n          \n          let r = sqrt(-2.0 * log(u1 + 1e-8));\n          let theta = 2.0 * 3.14159265359 * u2;\n          \n          return vec2<f32>(r * cos(theta), r * sin(theta));\n        }\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params[0];\n          let seed_base = params[1];\n          \n          if (index >= size) { return; }\n          \n          let seed1 = seed_base + index * 747796405u;\n          let seed2 = seed_base + index * 2891336453u + 1u;\n          \n          let normal_pair = random_normal(seed1, seed2);\n          output[index] = normal_pair.x;\n        }\n      `],["randint",e=>`\n        @group(0) @binding(0) var<storage, read_write> output: array<i32>;\n        @group(0) @binding(1) var<uniform> params: array<u32, 4>;\n\n        fn random_int(seed: u32, low: i32, high: i32) -> i32 {\n          let a = 1664525u;\n          let c = 1013904223u;\n          let m = 0xFFFFFFFFu;\n          let next_seed = (a * seed + c) % m;\n          let range = high - low;\n          return low + i32(next_seed % u32(range));\n        }\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params[0];\n          let seed_base = params[1];\n          let low = bitcast<i32>(params[2]);\n          let high = bitcast<i32>(params[3]);\n          \n          if (index >= size) { return; }\n          \n          let seed = seed_base + index * 747796405u;\n          output[index] = random_int(seed, low, high);\n        }\n      `],["zeros",e=>`\n        @group(0) @binding(0) var<storage, read_write> output: array<${e.dataType}>;\n        @group(0) @binding(1) var<uniform> params: array<u32, 4>;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params[0];\n          if (index >= size) { return; }\n          output[index] = 0.0;\n        }\n      `],["ones",e=>`\n        @group(0) @binding(0) var<storage, read_write> output: array<${e.dataType}>;\n        @group(0) @binding(1) var<uniform> params: array<u32, 4>;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params[0];\n          if (index >= size) { return; }\n          output[index] = 1.0;\n        }\n      `],["full",e=>`\n        @group(0) @binding(0) var<storage, read_write> output: array<${e.dataType}>;\n        @group(0) @binding(1) var<uniform> params: array<u32, 4>;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params[0];\n          let fill_value = bitcast<f32>(params[1]);\n          if (index >= size) { return; }\n          output[index] = fill_value;\n        }\n      `],["empty",e=>`\n        @group(0) @binding(0) var<storage, read_write> output: array<${e.dataType}>;\n        @group(0) @binding(1) var<uniform> params: array<u32, 4>;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params[0];\n          if (index >= size) { return; }\n          // Empty tensor - leave uninitialized (WebGPU will zero-initialize)\n          // In practice, this is similar to zeros but conceptually different\n        }\n      `],["cat",e=>`\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<${e.dataType}>;\n        @group(0) @binding(3) var<uniform> params: array<u32, 4>;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size1 = params[0];\n          let size2 = params[1];\n          let dim = params[2];  // Concatenation dimension\n          let total_size = size1 + size2;\n          \n          if (index >= total_size) { return; }\n          \n          // Simple concatenation along flattened dimension for now\n          if (index < size1) {\n            output[index] = input1[index];\n          } else {\n            output[index] = input2[index - size1];\n          }\n        }\n      `],["stack",e=>`\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<${e.dataType}>;\n        @group(0) @binding(3) var<uniform> params: array<u32, 4>;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let tensor_size = params[0];\n          let num_tensors = params[1];\n          let dim = params[2];  // Stack dimension\n          \n          if (index >= tensor_size * num_tensors) { return; }\n          \n          // Simple stacking - interleave elements\n          let tensor_idx = index / tensor_size;\n          let element_idx = index % tensor_size;\n          \n          if (tensor_idx == 0u) {\n            output[index] = input1[element_idx];\n          } else {\n            output[index] = input2[element_idx];\n          }\n        }\n      `],["chunk",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        @group(0) @binding(2) var<uniform> params: array<u32, 4>;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let input_size = params[0];\n          let num_chunks = params[1];\n          let chunk_idx = params[2];\n          let chunk_size = (input_size + num_chunks - 1u) / num_chunks;\n          \n          if (index >= chunk_size) { return; }\n          \n          let input_index = chunk_idx * chunk_size + index;\n          if (input_index < input_size) {\n            output[index] = input[input_index];\n          }\n        }\n      `],["split",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        @group(0) @binding(2) var<uniform> params: array<u32, 4>;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let split_size = params[0];\n          let split_idx = params[1];\n          let input_offset = split_idx * split_size;\n          \n          if (index >= split_size) { return; }\n          \n          output[index] = input[input_offset + index];\n        }\n      `],["max_reduce",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        @group(0) @binding(2) var<uniform> params: array<u32, 4>;\n\n        var<workgroup> shared_data: array<f32, ${e.workgroupSize[0]}>;\n\n        @compute @workgroup_size(${e.workgroupSize[0]})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>,\n                @builtin(local_invocation_id) local_id: vec3<u32>,\n                @builtin(workgroup_id) workgroup_id: vec3<u32>) {\n          let size = params[0];\n          let local_idx = local_id.x;\n          let global_idx = global_id.x;\n          \n          var max_val = -3.4028235e+38; // -FLT_MAX\n          for (var i = global_idx; i < size; i = i + ${e.workgroupSize[0]}u) {\n            max_val = max(max_val, input[i]);\n          }\n          shared_data[local_idx] = max_val;\n          \n          workgroupBarrier();\n          \n          for (var stride = ${e.workgroupSize[0]/2}u; stride > 0u; stride = stride >> 1u) {\n            if (local_idx < stride) {\n              shared_data[local_idx] = max(shared_data[local_idx], shared_data[local_idx + stride]);\n            }\n            workgroupBarrier();\n          }\n          \n          if (local_idx == 0u) {\n            output[workgroup_id.x] = shared_data[0];\n          }\n        }\n      `],["min_reduce",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        @group(0) @binding(2) var<uniform> params: array<u32, 4>;\n\n        var<workgroup> shared_data: array<f32, ${e.workgroupSize[0]}>;\n\n        @compute @workgroup_size(${e.workgroupSize[0]})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>,\n                @builtin(local_invocation_id) local_id: vec3<u32>,\n                @builtin(workgroup_id) workgroup_id: vec3<u32>) {\n          let size = params[0];\n          let local_idx = local_id.x;\n          let global_idx = global_id.x;\n          \n          var min_val = 3.4028235e+38; // FLT_MAX\n          for (var i = global_idx; i < size; i = i + ${e.workgroupSize[0]}u) {\n            min_val = min(min_val, input[i]);\n          }\n          shared_data[local_idx] = min_val;\n          \n          workgroupBarrier();\n          \n          for (var stride = ${e.workgroupSize[0]/2}u; stride > 0u; stride = stride >> 1u) {\n            if (local_idx < stride) {\n              shared_data[local_idx] = min(shared_data[local_idx], shared_data[local_idx + stride]);\n            }\n            workgroupBarrier();\n          }\n          \n          if (local_idx == 0u) {\n            output[workgroup_id.x] = shared_data[0];\n          }\n        }\n      `],["argmax",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<u32>;\n        @group(0) @binding(2) var<uniform> params: array<u32, 4>;\n\n        var<workgroup> shared_values: array<f32, ${e.workgroupSize[0]}>;\n        var<workgroup> shared_indices: array<u32, ${e.workgroupSize[0]}>;\n\n        @compute @workgroup_size(${e.workgroupSize[0]})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>,\n                @builtin(local_invocation_id) local_id: vec3<u32>,\n                @builtin(workgroup_id) workgroup_id: vec3<u32>) {\n          let size = params[0];\n          let local_idx = local_id.x;\n          let global_idx = global_id.x;\n          \n          var max_val = -3.4028235e+38; // -FLT_MAX\n          var max_idx = 0u;\n          \n          for (var i = global_idx; i < size; i = i + ${e.workgroupSize[0]}u) {\n            if (input[i] > max_val) {\n              max_val = input[i];\n              max_idx = i;\n            }\n          }\n          \n          shared_values[local_idx] = max_val;\n          shared_indices[local_idx] = max_idx;\n          \n          workgroupBarrier();\n          \n          for (var stride = ${e.workgroupSize[0]/2}u; stride > 0u; stride = stride >> 1u) {\n            if (local_idx < stride) {\n              if (shared_values[local_idx + stride] > shared_values[local_idx]) {\n                shared_values[local_idx] = shared_values[local_idx + stride];\n                shared_indices[local_idx] = shared_indices[local_idx + stride];\n              }\n            }\n            workgroupBarrier();\n          }\n          \n          if (local_idx == 0u) {\n            output[workgroup_id.x] = shared_indices[0];\n          }\n        }\n      `],["argmin",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<u32>;\n        @group(0) @binding(2) var<uniform> params: array<u32, 4>;\n\n        var<workgroup> shared_values: array<f32, ${e.workgroupSize[0]}>;\n        var<workgroup> shared_indices: array<u32, ${e.workgroupSize[0]}>;\n\n        @compute @workgroup_size(${e.workgroupSize[0]})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>,\n                @builtin(local_invocation_id) local_id: vec3<u32>,\n                @builtin(workgroup_id) workgroup_id: vec3<u32>) {\n          let size = params[0];\n          let local_idx = local_id.x;\n          let global_idx = global_id.x;\n          \n          var min_val = 3.4028235e+38; // FLT_MAX\n          var min_idx = 0u;\n          \n          for (var i = global_idx; i < size; i = i + ${e.workgroupSize[0]}u) {\n            if (input[i] < min_val) {\n              min_val = input[i];\n              min_idx = i;\n            }\n          }\n          \n          shared_values[local_idx] = min_val;\n          shared_indices[local_idx] = min_idx;\n          \n          workgroupBarrier();\n          \n          for (var stride = ${e.workgroupSize[0]/2}u; stride > 0u; stride = stride >> 1u) {\n            if (local_idx < stride) {\n              if (shared_values[local_idx + stride] < shared_values[local_idx]) {\n                shared_values[local_idx] = shared_values[local_idx + stride];\n                shared_indices[local_idx] = shared_indices[local_idx + stride];\n              }\n            }\n            workgroupBarrier();\n          }\n          \n          if (local_idx == 0u) {\n            output[workgroup_id.x] = shared_indices[0];\n          }\n        }\n      `],["eq",e=>`\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<u32>; // Boolean output as u32\n        @group(0) @binding(3) var<uniform> params: array<u32, 4>;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params[0];\n          if (index >= size) { return; }\n          output[index] = u32(input1[index] == input2[index]);\n        }\n      `],["gt",e=>`\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<u32>;\n        @group(0) @binding(3) var<uniform> params: array<u32, 4>;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params[0];\n          if (index >= size) { return; }\n          output[index] = u32(input1[index] > input2[index]);\n        }\n      `],["lt",e=>`\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<u32>;\n        @group(0) @binding(3) var<uniform> params: array<u32, 4>;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params[0];\n          if (index >= size) { return; }\n          output[index] = u32(input1[index] < input2[index]);\n        }\n      `],["ge",e=>`\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<u32>;\n        @group(0) @binding(3) var<uniform> params: array<u32, 4>;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params[0];\n          if (index >= size) { return; }\n          output[index] = u32(input1[index] >= input2[index]);\n        }\n      `],["le",e=>`\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<u32>;\n        @group(0) @binding(3) var<uniform> params: array<u32, 4>;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params[0];\n          if (index >= size) { return; }\n          output[index] = u32(input1[index] <= input2[index]);\n        }\n      `],["equal",e=>`\n        @group(0) @binding(0) var<storage, read> input1: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> input2: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<u32>;\n        @group(0) @binding(3) var<uniform> params: array<u32, 4>;\n\n        var<workgroup> shared_result: u32;\n\n        @compute @workgroup_size(${e.workgroupSize[0]})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>,\n                @builtin(local_invocation_id) local_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params[0];\n          let local_idx = local_id.x;\n          \n          var is_equal = 1u;\n          for (var i = index; i < size; i = i + ${e.workgroupSize[0]}u) {\n            if (input1[i] != input2[i]) {\n              is_equal = 0u;\n              break;\n            }\n          }\n          \n          // Reduction to find if all elements are equal\n          workgroupBarrier();\n          if (local_idx == 0u) {\n            shared_result = is_equal;\n          }\n          workgroupBarrier();\n          \n          shared_result = shared_result & is_equal;\n          workgroupBarrier();\n          \n          if (local_idx == 0u) {\n            output[0] = shared_result;\n          }\n        }\n      `],["cross_entropy",e=>`\n        @group(0) @binding(0) var<storage, read> logits: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> targets: array<u32>;\n        @group(0) @binding(2) var<storage, read_write> output: array<${e.dataType}>;\n        @group(0) @binding(3) var<uniform> params: array<u32, 4>;\n\n        @compute @workgroup_size(${e.workgroupSize[0]})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let batch_idx = global_id.x;\n          let batch_size = params[0];\n          let num_classes = params[1];\n          \n          if (batch_idx >= batch_size) { return; }\n          \n          let batch_offset = batch_idx * num_classes;\n          let target_class = targets[batch_idx];\n          \n          // Find max for numerical stability\n          var max_logit = -3.4028235e+38;\n          for (var i = 0u; i < num_classes; i = i + 1u) {\n            max_logit = max(max_logit, logits[batch_offset + i]);\n          }\n          \n          // Compute log-sum-exp\n          var sum_exp = 0.0;\n          for (var i = 0u; i < num_classes; i = i + 1u) {\n            sum_exp = sum_exp + exp(logits[batch_offset + i] - max_logit);\n          }\n          let log_sum_exp = log(sum_exp) + max_logit;\n          \n          // Cross entropy loss = -log(softmax[target])\n          let target_logit = logits[batch_offset + target_class];\n          output[batch_idx] = log_sum_exp - target_logit;\n        }\n      `],["mse_loss",e=>`\n        @group(0) @binding(0) var<storage, read> predictions: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read> targets: array<${e.dataType}>;\n        @group(0) @binding(2) var<storage, read_write> output: array<${e.dataType}>;\n        @group(0) @binding(3) var<uniform> params: array<u32, 4>;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params[0];\n          if (index >= size) { return; }\n          let diff = predictions[index] - targets[index];\n          output[index] = diff * diff;\n        }\n      `],["reshape",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        @group(0) @binding(2) var<uniform> params: array<u32, 8>;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params[0];\n          if (index >= size) { return; }\n          \n          // Simple copy operation - reshape is just a metadata change\n          output[index] = input[index];\n        }\n      `],["squeeze",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        @group(0) @binding(2) var<uniform> params: array<u32, 8>;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params[0];\n          if (index >= size) { return; }\n          \n          // Copy data while removing dimensions of size 1\n          output[index] = input[index];\n        }\n      `],["unsqueeze",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        @group(0) @binding(2) var<uniform> params: array<u32, 8>;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {\n          let index = global_id.x;\n          let size = params[0];\n          if (index >= size) { return; }\n          \n          // Copy data while adding dimensions of size 1\n          output[index] = input[index];\n        }\n      `],["std",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        @group(0) @binding(2) var<uniform> params: array<u32, 8>;\n\n        var<workgroup> local_data: array<${e.dataType}, ${e.workgroupSize[0]}>;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>,\n                @builtin(local_invocation_id) local_id: vec3<u32>) {\n          let index = global_id.x;\n          let local_index = local_id.x;\n          let size = params[0];\n          let mean_val = bitcast<${e.dataType}>(params[1]);\n          \n          // Load data into workgroup memory\n          if (index < size) {\n            let diff = input[index] - mean_val;\n            local_data[local_index] = diff * diff;\n          } else {\n            local_data[local_index] = 0.0;\n          }\n          \n          workgroupBarrier();\n          \n          // Parallel reduction for sum of squared differences\n          var stride = ${e.workgroupSize[0]} / 2u;\n          while (stride > 0u) {\n            if (local_index < stride && (index + stride) < size) {\n              local_data[local_index] += local_data[local_index + stride];\n            }\n            workgroupBarrier();\n            stride = stride / 2u;\n          }\n          \n          // Write result (sqrt of variance)\n          if (local_index == 0u) {\n            let variance = local_data[0] / ${e.dataType}(size - 1u);\n            output[global_id.x / ${e.workgroupSize[0]}] = sqrt(variance);\n          }\n        }\n      `],["var",e=>`\n        @group(0) @binding(0) var<storage, read> input: array<${e.dataType}>;\n        @group(0) @binding(1) var<storage, read_write> output: array<${e.dataType}>;\n        @group(0) @binding(2) var<uniform> params: array<u32, 8>;\n\n        var<workgroup> local_data: array<${e.dataType}, ${e.workgroupSize[0]}>;\n\n        @compute @workgroup_size(${e.workgroupSize.join(", ")})\n        fn main(@builtin(global_invocation_id) global_id: vec3<u32>,\n                @builtin(local_invocation_id) local_id: vec3<u32>) {\n          let index = global_id.x;\n          let local_index = local_id.x;\n          let size = params[0];\n          let mean_val = bitcast<${e.dataType}>(params[1]);\n          \n          // Load data into workgroup memory\n          if (index < size) {\n            let diff = input[index] - mean_val;\n            local_data[local_index] = diff * diff;\n          } else {\n            local_data[local_index] = 0.0;\n          }\n          \n          workgroupBarrier();\n          \n          // Parallel reduction for sum of squared differences\n          var stride = ${e.workgroupSize[0]} / 2u;\n          while (stride > 0u) {\n            if (local_index < stride && (index + stride) < size) {\n              local_data[local_index] += local_data[local_index + stride];\n            }\n            workgroupBarrier();\n            stride = stride / 2u;\n          }\n          \n          // Write variance result\n          if (local_index == 0u) {\n            output[global_id.x / ${e.workgroupSize[0]}] = local_data[0] / ${e.dataType}(size - 1u);\n          }\n        }\n      `]])}static getOptimalWorkgroupSize(e,t,r){const i=r?.maxComputeWorkgroupSizeX||256;switch(e){case"matmul":case"bmm":return[Math.min(16,i),Math.min(16,i),1];case"conv2d":return[Math.min(8,i),Math.min(8,i),Math.min(8,i)];case"softmax":case"sum":case"mean":return[Math.min(256,i),1,1];default:return[Math.min(64,i),1,1]}}static getBufferLayout(e,t=2,r=1){return{add:{inputs:2,outputs:1,uniforms:1},sub:{inputs:2,outputs:1,uniforms:1},mul:{inputs:2,outputs:1,uniforms:1},div:{inputs:2,outputs:1,uniforms:1},pow:{inputs:2,outputs:1,uniforms:1},matmul:{inputs:2,outputs:1,uniforms:1},bmm:{inputs:2,outputs:1,uniforms:1},rand:{inputs:0,outputs:1,uniforms:1},randn:{inputs:0,outputs:1,uniforms:1},randint:{inputs:0,outputs:1,uniforms:1},zeros:{inputs:0,outputs:1,uniforms:1},ones:{inputs:0,outputs:1,uniforms:1},full:{inputs:0,outputs:1,uniforms:1},empty:{inputs:0,outputs:1,uniforms:1},cat:{inputs:2,outputs:1,uniforms:1},stack:{inputs:2,outputs:1,uniforms:1},chunk:{inputs:1,outputs:1,uniforms:1},split:{inputs:1,outputs:1,uniforms:1},max_reduce:{inputs:1,outputs:1,uniforms:1},min_reduce:{inputs:1,outputs:1,uniforms:1},argmax:{inputs:1,outputs:1,uniforms:1},argmin:{inputs:1,outputs:1,uniforms:1},eq:{inputs:2,outputs:1,uniforms:1},gt:{inputs:2,outputs:1,uniforms:1},lt:{inputs:2,outputs:1,uniforms:1},ge:{inputs:2,outputs:1,uniforms:1},le:{inputs:2,outputs:1,uniforms:1},equal:{inputs:2,outputs:1,uniforms:1},relu:{inputs:1,outputs:1,uniforms:1},sigmoid:{inputs:1,outputs:1,uniforms:1},tanh:{inputs:1,outputs:1,uniforms:1},exp:{inputs:1,outputs:1,uniforms:1},log:{inputs:1,outputs:1,uniforms:1},sqrt:{inputs:1,outputs:1,uniforms:1},abs:{inputs:1,outputs:1,uniforms:1},conv2d:{inputs:3,outputs:1,uniforms:1},batch_norm:{inputs:5,outputs:1,uniforms:1},cross_entropy:{inputs:2,outputs:1,uniforms:1},sum:{inputs:1,outputs:1,uniforms:1},mean:{inputs:1,outputs:1,uniforms:1}}[e]||{inputs:t,outputs:r,uniforms:1}}static generateParams(e,t,r={}){const i=new Uint32Array(4);switch(e){case"matmul":i[0]=t[0].shape?.[0]||Math.sqrt(t[0].length),i[1]=t[1].shape?.[1]||Math.sqrt(t[1].length),i[2]=t[0].shape?.[1]||Math.sqrt(t[0].length);break;case"bmm":i[0]=t[0].shape?.[0]||1,i[1]=t[0].shape?.[1]||Math.sqrt(t[0].length),i[2]=t[1].shape?.[2]||Math.sqrt(t[1].length),i[3]=t[0].shape?.[2]||Math.sqrt(t[0].length);break;case"conv2d":const e=t[0].shape||[1,1,28,28];t[1].shape,i[0]=e[0],i[1]=e[1],i[2]=e[2],i[3]=e[3];break;case"softmax":const n=t[0].shape||[1,t[0].length];i[0]=n.length>1?n[0]:1,i[1]=n.length>1?n[1]:n[0];break;case"leaky_relu":i[0]=t[0].length,i[1]=new Uint32Array(new Float32Array([r.negativeSlope||.01]).buffer)[0];break;case"rand":case"randn":i[0]=r.size||r.shape?.reduce((e,t)=>e*t,1)||1,i[1]=r.seed||Math.floor(4294967295*Math.random());break;case"randint":i[0]=r.size||r.shape?.reduce((e,t)=>e*t,1)||1,i[1]=r.seed||Math.floor(4294967295*Math.random()),i[2]=new Uint32Array(new Int32Array([r.low||0]).buffer)[0],i[3]=new Uint32Array(new Int32Array([r.high||10]).buffer)[0];break;case"zeros":case"ones":case"empty":i[0]=r.size||r.shape?.reduce((e,t)=>e*t,1)||1;break;case"full":i[0]=r.size||r.shape?.reduce((e,t)=>e*t,1)||1,i[1]=new Uint32Array(new Float32Array([r.fillValue||0]).buffer)[0];break;case"cat":i[0]=t[0].length,i[1]=t[1].length,i[2]=r.dim||0;break;case"stack":i[0]=t[0].length,i[1]=t.length,i[2]=r.dim||0;break;case"chunk":i[0]=t[0].length,i[1]=r.chunks||2,i[2]=r.chunkIdx||0;break;case"split":i[0]=r.splitSize||Math.floor(t[0].length/(r.splits||2)),i[1]=r.splitIdx||0;break;case"max_reduce":case"min_reduce":case"argmax":case"argmin":i[0]=t[0].length,i[1]=r.dim||0,i[2]=r.keepdim?1:0;break;case"eq":case"gt":case"lt":case"ge":case"le":case"equal":i[0]=Math.max(t[0].length,t[1].length);break;default:i[0]=Array.isArray(t)?t[0].length:t.length}return i}}class o extends i.A{constructor(e,t={}){super(),this.device=e,this.config={maxCacheSize:t.maxCacheSize||100,enableWarmup:!1!==t.enableWarmup,enableMetrics:!1!==t.enableMetrics,shaderOptimization:t.shaderOptimization||"balanced",...t},this.pipelines=new Map,this.shaderModules=new Map,this.bindGroupLayouts=new Map,this.accessOrder=new Map,this.compilationQueue=new Map,this.stats={hits:0,misses:0,compilations:0,evictions:0,averageCompileTime:0,totalCompileTime:0},this.shaderTemplates=s.getShaderTemplates()}async get(e,t={}){const r=this._generateKey(e,t);if(this.pipelines.has(r))return this._updateAccess(r),this.stats.hits++,this.emit("cache:hit",{operation:e,key:r}),this.pipelines.get(r);if(this.compilationQueue.has(r))return this.emit("cache:wait",{operation:e,key:r}),await this.compilationQueue.get(r);this.stats.misses++,this.emit("cache:miss",{operation:e,key:r});const i=this._compilePipeline(e,t,r);this.compilationQueue.set(r,i);try{const e=await i;return this.compilationQueue.delete(r),e}catch(e){throw this.compilationQueue.delete(r),e}}async warmup(e=null){if(!this.config.enableWarmup)return;const t=e||["add","multiply","matmul","relu","sigmoid","softmax","conv2d","maxpool","transpose"];this.emit("warmup:start",{operations:t});const r=performance.now(),i=t.map(async e=>{try{await this.get(e,{warmup:!0}),this.emit("warmup:operation",{operation:e})}catch(t){this.emit("warmup:error",{operation:e,error:t})}});await Promise.allSettled(i);const n=performance.now()-r;this.emit("warmup:complete",{operations:t,duration:n})}getBindGroupLayout(e,t={}){const r=this._generateLayoutKey(e,t);if(this.bindGroupLayouts.has(r))return this.bindGroupLayouts.get(r);const i=this._createBindGroupLayout(e,t);return this.bindGroupLayouts.set(r,i),i}getOptimalWorkgroupSize(e,t,r){return s.getOptimalWorkgroupSize(e,t,r)}generateOperationParams(e,t,r={}){return s.generateParams(e,t,r)}async createShaderModule(e,t={}){const r=this._hashString(e);if(this.shaderModules.has(r))return this.shaderModules.get(r);try{const i=this.device.createShaderModule({code:e,...t});return this.shaderModules.set(r,i),this.emit("shader:compiled",{hash:r,size:e.length}),i}catch(t){throw this.emit("shader:error",{hash:r,error:t,source:e.substring(0,100)}),t}}generateShader(e,t={}){const r=this.shaderTemplates[e];if(!r)throw new Error(`No shader template found for operation: ${e}`);return r({workgroupSize:t.workgroupSize||[8,8,1],dataType:t.dataType||"f32",optimization:this.config.shaderOptimization,...t})}getStats(){const e=this.stats.hits+this.stats.misses>0?this.stats.hits/(this.stats.hits+this.stats.misses):0;return{...this.stats,hitRate:e,cacheSize:this.pipelines.size,shaderCacheSize:this.shaderModules.size,layoutCacheSize:this.bindGroupLayouts.size,averageCompileTimeMs:Math.round(100*this.stats.averageCompileTime)/100}}clear(){this.pipelines.clear(),this.shaderModules.clear(),this.bindGroupLayouts.clear(),this.accessOrder.clear(),this.compilationQueue.clear(),this.stats.hits=0,this.stats.misses=0,this.emit("cache:cleared")}cleanup(){this.clear(),this.shaderTemplates.clear(),this.emit("cleanup:complete")}async _compilePipeline(e,t,r){const i=performance.now();try{const n=this.generateShader(e,t),a=await this.createShaderModule(n),s=this.getBindGroupLayout(e,t),o=this.device.createPipelineLayout({bindGroupLayouts:[s]}),u=await this.device.createComputePipelineAsync({layout:o,compute:{module:a,entryPoint:"main"}});this.pipelines.set(r,u),this._updateAccess(r),this._enforceMaxCacheSize();const p=performance.now()-i;return this.stats.compilations++,this.stats.totalCompileTime+=p,this.stats.averageCompileTime=this.stats.totalCompileTime/this.stats.compilations,this.emit("pipeline:compiled",{operation:e,key:r,compileTime:p,cacheSize:this.pipelines.size}),u}catch(t){throw this.emit("pipeline:error",{operation:e,key:r,error:t}),t}}_generateKey(e,t){return[e,t.workgroupSize?.join(",")||"8,8,1",t.dataType||"f32",t.inputCount||2,t.outputCount||1,JSON.stringify(t.constants||{})].join("|")}_generateLayoutKey(e,t){return`${e}|${t.inputCount||2}|${t.outputCount||1}`}_createBindGroupLayout(e,t){const r=s.getBufferLayout(e,t.inputCount,t.outputCount),i=[];for(let e=0;e<r.inputs;e++)i.push({binding:e,visibility:GPUShaderStage.COMPUTE,buffer:{type:"read-only-storage"}});for(let e=0;e<r.outputs;e++)i.push({binding:r.inputs+e,visibility:GPUShaderStage.COMPUTE,buffer:{type:"storage"}});return r.uniforms>0&&i.push({binding:r.inputs+r.outputs,visibility:GPUShaderStage.COMPUTE,buffer:{type:"uniform"}}),this.device.createBindGroupLayout({entries:i})}_updateAccess(e){this.accessOrder.set(e,performance.now())}_enforceMaxCacheSize(){if(this.pipelines.size<=this.config.maxCacheSize)return;let e=null,t=1/0;for(const[r,i]of this.accessOrder.entries())i<t&&(t=i,e=r);e&&(this.pipelines.delete(e),this.accessOrder.delete(e),this.stats.evictions++,this.emit("cache:eviction",{key:e,cacheSize:this.pipelines.size}))}_hashString(e){let t=0;for(let r=0;r<e.length;r++)t=(t<<5)-t+e.charCodeAt(r),t&=t;return t.toString(36)}}const u=o;var p=r(626);class l extends i.A{constructor(e={}){super(),this.config={powerPreference:e.powerPreference||"high-performance",enableProfiling:!1!==e.enableProfiling,maxBufferSize:e.maxBufferSize||268435456,workgroupSize:e.workgroupSize||[64,1,1],enableValidation:!1!==e.enableValidation,...e},this.adapter=null,this.device=null,this.isInitialized=!1,this.bufferManager=null,this.pipelineCache=null,this.supportedFeatures=new Set,this.limits=null,this.stats={computeOperations:0,totalExecutionTime:0,averageExecutionTime:0,memoryUsage:0,lastOperationTime:0}}async initialize(){if(this.isInitialized)return!0;try{if(this.emit("init:start"),!navigator.gpu)throw new Error("WebGPU not supported in this browser");if(this.adapter=await navigator.gpu.requestAdapter({powerPreference:this.config.powerPreference}),!this.adapter)throw new Error("Failed to get WebGPU adapter");this.supportedFeatures=this.adapter.features,this.limits=this.adapter.limits,this.emit("init:adapter",{features:Array.from(this.supportedFeatures),limits:this.limits});const e={requiredFeatures:[],requiredLimits:{}};return this.supportedFeatures.has("timestamp-query")&&e.requiredFeatures.push("timestamp-query"),this.device=await this.adapter.requestDevice(e),this.device.addEventListener("uncapturederror",e=>{const t=e.error;this.emit("device:error",{error:t,type:"uncaptured",timestamp:Date.now()}),p.A.error("WebGPU uncaptured error:",{type:t.constructor.name,message:t.message,stack:t.stack}),this._handleDeviceError(t)}),this.bufferManager=new a(this.device,{maxBufferSize:this.config.maxBufferSize,enablePooling:!0,maxPoolSize:100}),this.pipelineCache=new u(this.device,{maxCacheSize:50,enableWarmup:!0,shaderOptimization:"balanced"}),this._setupEventForwarding(),await this.pipelineCache.warmup(),this.isInitialized=!0,this.emit("init:complete",{device:this.device,features:Array.from(this.supportedFeatures)}),!0}catch(e){return this.emit("init:error",{error:e,timestamp:Date.now()}),p.A.error("WebGPU initialization failed:",{type:e.constructor.name,message:e.message,stack:e.stack,config:this.config}),this.isInitialized=!1,this.initFailureReason=e.message,!1}}async execute(e,t,r={}){if(!this.isInitialized)throw new Error("WebGPU compute engine not initialized");const i=performance.now();this.emit("compute:start",{operation:e,options:r});try{this._validateOperation(e,t,r);const n=Array.isArray(t)?t:[t],a=this.pipelineCache.getOptimalWorkgroupSize(e,n[0].shape||[n[0].length],this.limits),s=await this.pipelineCache.get(e,{workgroupSize:r.workgroupSize||a,dataType:r.dataType||"f32",inputCount:n.length,outputCount:r.outputCount||1,...r}),o=await this._prepareBuffers(t,e,r),u=this._createBindGroup(s,o,r),p=await this._executeComputePass(s,u,o,r),l=performance.now()-i;return this._updateStats(e,l,o),this.emit("compute:complete",{operation:e,executionTime:l,resultSize:p.length}),p}catch(n){const a=performance.now()-i,s={operation:e,error:{type:n.constructor.name,message:n.message,stack:n.stack},executionTime:a,tensors:Array.isArray(t)?t.length:1,options:r,deviceStable:this.deviceStable??!0,timestamp:Date.now()};throw this.emit("compute:error",s),p.A.error("WebGPU compute operation failed:",s),(n.message.includes("out of memory")||"GPUOutOfMemoryError"===n.constructor.name)&&(p.A.warn("GPU memory exhausted, attempting emergency cleanup"),await this.bufferManager.emergencyCleanup(),this.emit("recovery:memory",{operation:e,timestamp:Date.now()})),n}}async executeBatch(e,t={}){const{parallel:r=!1,maxConcurrency:i=4}=t;if(r){const t=new d(i),r=e.map(async e=>{await t.acquire();try{return await this.execute(e.operation,e.tensors,e.options)}finally{t.release()}});return Promise.all(r)}{const t=[];for(const r of e){const e=await this.execute(r.operation,r.tensors,r.options);t.push(e)}return t}}async uploadTensor(e,t={}){const{usage:r=GPUBufferUsage.STORAGE|GPUBufferUsage.COPY_DST}=t;return this.bufferManager.createMappedBuffer(e,r)}async downloadTensor(e,t,r={}){const{format:i=Float32Array}=r,n=this.bufferManager.allocate(4*t,GPUBufferUsage.COPY_DST|GPUBufferUsage.MAP_READ);try{const r=this.device.createCommandEncoder();r.copyBufferToBuffer(e,0,n,0,4*t),this.device.queue.submit([r.finish()]),await n.mapAsync(GPUMapMode.READ);const a=new i(n.getMappedRange().slice());return n.unmap(),a}finally{this.bufferManager.release(n,{forceDestroy:!0})}}getStats(){return{...this.stats,bufferStats:this.bufferManager?.getStats()||{},pipelineStats:this.pipelineCache?.getStats()||{},deviceLimits:this.limits,supportedFeatures:Array.from(this.supportedFeatures||[])}}async cleanup(){this.emit("cleanup:start");try{this.bufferManager&&(await this.bufferManager.cleanup(),this.bufferManager=null),this.pipelineCache&&(this.pipelineCache.cleanup(),this.pipelineCache=null),this.device&&(this.device.destroy(),this.device=null),this.adapter=null,this.isInitialized=!1,this.emit("cleanup:complete")}catch(e){throw this.emit("cleanup:error",{error:e}),e}}_validateOperation(e,t,r){if(!e||"string"!=typeof e)throw new Error("Operation must be a non-empty string");if(!t)throw new Error("Tensors parameter is required");const i=Array.isArray(t)?t:[t];for(const e of i)if(!e||!ArrayBuffer.isView(e)&&!(e instanceof ArrayBuffer))throw new Error("All tensors must be typed arrays or ArrayBuffers")}async _prepareBuffers(e,t,r){const i=Array.isArray(e)?e:[e],n={inputs:[],output:null,params:null};for(const e of i){const t=await this.uploadTensor(e);n.inputs.push(t)}const a=this._calculateOutputSize(t,i,r);n.output=this.bufferManager.allocate(4*a,GPUBufferUsage.STORAGE|GPUBufferUsage.COPY_SRC);const s=this.pipelineCache.generateOperationParams(t,i,r);return n.params=await this.uploadTensor(s,{usage:GPUBufferUsage.UNIFORM|GPUBufferUsage.COPY_DST}),n}_createBindGroup(e,t,r){const i=[];for(let e=0;e<t.inputs.length;e++)i.push({binding:e,resource:{buffer:t.inputs[e]}});return i.push({binding:t.inputs.length,resource:{buffer:t.output}}),i.push({binding:t.inputs.length+1,resource:{buffer:t.params}}),this.device.createBindGroup({layout:e.getBindGroupLayout(0),entries:i})}async _executeComputePass(e,t,r,i){const n=this.device.createCommandEncoder(),a=n.beginComputePass();a.setPipeline(e),a.setBindGroup(0,t);const s=i.workgroupSize||this.config.workgroupSize,o=r.output.size/4,u=Math.ceil(o/s[0]);return a.dispatchWorkgroups(u,1,1),a.end(),this.device.queue.submit([n.finish()]),await this.device.queue.onSubmittedWorkDone(),this.downloadTensor(r.output,o)}_calculateOutputSize(e,t,r){if(r.outputSize)return r.outputSize;const i=t[0],n=e=>ArrayBuffer.isView(e)?e.length:e.byteLength/4;switch(e){case"matmul":return(t[0].shape?.[0]||Math.sqrt(n(t[0])))*(t[1].shape?.[1]||Math.sqrt(n(t[1])));case"bmm":const e=t[0].shape?.[0]||1;return e*(t[0].shape?.[1]||Math.sqrt(n(t[0])/e))*(t[1].shape?.[2]||Math.sqrt(n(t[1])/e));case"conv2d":const a=t[0].shape?.[2]||28,s=t[0].shape?.[3]||28,o=t[1].shape?.[0]||32;return(t[0].shape?.[0]||1)*o*a*s;case"transpose":case"softmax":default:return n(i);case"sum":case"mean":return r.keepDim?n(i):1;case"maxpool2d":case"avgpool2d":const u=r.kernelSize||2,p=r.stride||u,l=t[0].shape?.[2]||28,d=t[0].shape?.[3]||28,c=Math.floor((l-u)/p)+1,h=Math.floor((d-u)/p)+1,g=t[0].shape?.[1]||1;return(t[0].shape?.[0]||1)*g*c*h}}_updateStats(e,t,r){this.stats.computeOperations++,this.stats.totalExecutionTime+=t,this.stats.averageExecutionTime=this.stats.totalExecutionTime/this.stats.computeOperations,this.stats.lastOperationTime=t;const i=r.inputs.reduce((e,t)=>e+t.size,0)+r.output.size;this.stats.memoryUsage=Math.max(this.stats.memoryUsage,i)}_setupEventForwarding(){this.bufferManager.on("buffer:created",e=>this.emit("buffer:created",e)),this.bufferManager.on("buffer:destroyed",e=>this.emit("buffer:destroyed",e)),this.bufferManager.on("gc:complete",e=>this.emit("buffer:gc",e)),this.pipelineCache.on("cache:miss",e=>this.emit("pipeline:miss",e)),this.pipelineCache.on("pipeline:compiled",e=>this.emit("pipeline:compiled",e)),this.pipelineCache.on("warmup:complete",e=>this.emit("pipeline:warmup",e))}_handleDeviceError(e){const t=e.constructor.name;switch(t){case"GPUOutOfMemoryError":p.A.warn("GPU out of memory, attempting buffer cleanup"),this.bufferManager.emergencyCleanup(),this.emit("recovery:attempt",{type:"memory-cleanup",timestamp:Date.now()});break;case"GPUInternalError":p.A.warn("GPU internal error, marking device as potentially unstable"),this.deviceStable=!1,this.emit("device:unstable",{reason:"internal-error",timestamp:Date.now()});break;case"GPUValidationError":p.A.warn("GPU validation error, this may indicate shader or pipeline issues"),this.emit("validation:error",{error:e,timestamp:Date.now()});break;default:p.A.warn("Unknown GPU error type:",t),this.emit("error:unknown",{error:e,timestamp:Date.now()})}}getErrorDiagnostics(){return{isInitialized:this.isInitialized,deviceStable:this.deviceStable??!0,initFailureReason:this.initFailureReason||null,bufferStats:this.bufferManager?.getStats()||null,pipelineStats:this.pipelineCache?.getStats()||null,supportedFeatures:Array.from(this.supportedFeatures||[]),timestamp:Date.now()}}}class d{constructor(e){this.max=e,this.current=0,this.queue=[]}async acquire(){return new Promise(e=>{this.current<this.max?(this.current++,e()):this.queue.push(e)})}release(){if(this.current--,this.queue.length>0){const e=this.queue.shift();this.current++,e()}}}const c=l;class h extends i.A{constructor(e={}){super(),this.config={enableOptimizations:!1!==e.enableOptimizations,maxConcurrentOps:e.maxConcurrentOps||2,enableProfiling:!1!==e.enableProfiling,chunkSize:e.chunkSize||1e4,...e},this.isInitialized=!1,this.runtime=null,this.numpy=null,this.stats={operations:0,totalExecutionTime:0,averageExecutionTime:0,lastOperationTime:0,supportedOperations:new Set(["add","subtract","multiply","divide","matmul","transpose","reshape","sum","mean","max","min","relu","sigmoid","tanh","softmax","exp","log","sqrt","power","abs","sign","clip"])},this.operations=this._initializeOperations()}async initialize(e=null){if(this.isInitialized)return!0;try{return this.emit("init:start"),e&&(this.runtime=e,this.numpy=e.getGlobal("np")),this.runtime&&await this._installCPUOperations(),this.isInitialized=!0,this.emit("init:complete",{supportedOperations:Array.from(this.stats.supportedOperations)}),!0}catch(e){throw this.emit("init:error",{error:e}),e}}async execute(e,t,r={}){if(!this.isInitialized)throw new Error("CPU engine not initialized");const i=performance.now();this.emit("compute:start",{operation:e,options:r});try{if(!this.stats.supportedOperations.has(e))throw new Error(`Unsupported CPU operation: ${e}`);const n=this.operations[e];if(!n)throw new Error(`Operation implementation not found: ${e}`);const a=await n(t,r),s=performance.now()-i;return this._updateStats(s),this.emit("compute:complete",{operation:e,executionTime:s,resultSize:this._getResultSize(a)}),a}catch(t){const r=performance.now()-i;throw this.emit("compute:error",{operation:e,error:t,executionTime:r}),t}}async executeBatch(e,t={}){const{sequential:r=!1}=t;if(r){const t=[];for(const r of e){const e=await this.execute(r.operation,r.tensors,r.options);t.push(e)}return t}{const t=new g(this.config.maxConcurrentOps),r=e.map(async e=>{await t.acquire();try{return await this.execute(e.operation,e.tensors,e.options)}finally{t.release()}});return Promise.all(r)}}getStats(){return{...this.stats,isInitialized:this.isInitialized,config:this.config,type:"cpu"}}async cleanup(){try{this.emit("cleanup:start"),this.isInitialized=!1,this.runtime=null,this.numpy=null,this.emit("cleanup:complete")}catch(e){throw this.emit("cleanup:error",{error:e}),e}}async _installCPUOperations(){await this.runtime.runPython('\nimport numpy as np\nfrom typing import Union, List, Tuple, Optional\n\nclass CPUTensorOps:\n    """CPU-optimized tensor operations using NumPy"""\n    \n    @staticmethod\n    def add(a: np.ndarray, b: np.ndarray) -> np.ndarray:\n        return np.add(a, b)\n    \n    @staticmethod\n    def subtract(a: np.ndarray, b: np.ndarray) -> np.ndarray:\n        return np.subtract(a, b)\n    \n    @staticmethod\n    def multiply(a: np.ndarray, b: np.ndarray) -> np.ndarray:\n        return np.multiply(a, b)\n    \n    @staticmethod\n    def divide(a: np.ndarray, b: np.ndarray) -> np.ndarray:\n        return np.divide(a, b)\n    \n    @staticmethod\n    def matmul(a: np.ndarray, b: np.ndarray) -> np.ndarray:\n        return np.matmul(a, b)\n    \n    @staticmethod\n    def transpose(a: np.ndarray, axes: Optional[Tuple] = None) -> np.ndarray:\n        return np.transpose(a, axes)\n    \n    @staticmethod\n    def reshape(a: np.ndarray, shape: Tuple) -> np.ndarray:\n        return np.reshape(a, shape)\n    \n    @staticmethod\n    def sum(a: np.ndarray, axis: Optional[Union[int, Tuple]] = None, keepdims: bool = False) -> np.ndarray:\n        return np.sum(a, axis=axis, keepdims=keepdims)\n    \n    @staticmethod\n    def mean(a: np.ndarray, axis: Optional[Union[int, Tuple]] = None, keepdims: bool = False) -> np.ndarray:\n        return np.mean(a, axis=axis, keepdims=keepdims)\n    \n    @staticmethod\n    def max(a: np.ndarray, axis: Optional[Union[int, Tuple]] = None, keepdims: bool = False) -> np.ndarray:\n        return np.max(a, axis=axis, keepdims=keepdims)\n    \n    @staticmethod\n    def min(a: np.ndarray, axis: Optional[Union[int, Tuple]] = None, keepdims: bool = False) -> np.ndarray:\n        return np.min(a, axis=axis, keepdims=keepdims)\n    \n    @staticmethod\n    def relu(a: np.ndarray) -> np.ndarray:\n        return np.maximum(a, 0)\n    \n    @staticmethod\n    def sigmoid(a: np.ndarray) -> np.ndarray:\n        return 1 / (1 + np.exp(-np.clip(a, -250, 250)))  # Prevent overflow\n    \n    @staticmethod\n    def tanh(a: np.ndarray) -> np.ndarray:\n        return np.tanh(a)\n    \n    @staticmethod\n    def softmax(a: np.ndarray, axis: int = -1) -> np.ndarray:\n        # Stable softmax implementation\n        x_max = np.max(a, axis=axis, keepdims=True)\n        exp_x = np.exp(a - x_max)\n        return exp_x / np.sum(exp_x, axis=axis, keepdims=True)\n    \n    @staticmethod\n    def exp(a: np.ndarray) -> np.ndarray:\n        return np.exp(np.clip(a, -250, 250))  # Prevent overflow\n    \n    @staticmethod\n    def log(a: np.ndarray) -> np.ndarray:\n        return np.log(np.maximum(a, 1e-12))  # Prevent log(0)\n    \n    @staticmethod\n    def sqrt(a: np.ndarray) -> np.ndarray:\n        return np.sqrt(np.maximum(a, 0))  # Prevent sqrt of negative\n    \n    @staticmethod\n    def power(a: np.ndarray, b: Union[np.ndarray, float]) -> np.ndarray:\n        return np.power(a, b)\n    \n    @staticmethod\n    def abs(a: np.ndarray) -> np.ndarray:\n        return np.abs(a)\n    \n    @staticmethod\n    def sign(a: np.ndarray) -> np.ndarray:\n        return np.sign(a)\n    \n    @staticmethod\n    def clip(a: np.ndarray, min_val: float, max_val: float) -> np.ndarray:\n        return np.clip(a, min_val, max_val)\n\n# Install globally\ncpu_ops = CPUTensorOps()\n',{captureOutput:!1}),this.emit("operations:installed",{count:this.stats.supportedOperations.size})}_initializeOperations(){return{add:async(e,t)=>this._executePythonOp("cpu_ops.add",e,t),subtract:async(e,t)=>this._executePythonOp("cpu_ops.subtract",e,t),multiply:async(e,t)=>this._executePythonOp("cpu_ops.multiply",e,t),divide:async(e,t)=>this._executePythonOp("cpu_ops.divide",e,t),matmul:async(e,t)=>this._executePythonOp("cpu_ops.matmul",e,t),transpose:async(e,t)=>{const r=t.axes?`axes=${JSON.stringify(t.axes)}`:"";return this._executePythonOp("cpu_ops.transpose",e,{axes:r})},reshape:async(e,t)=>{if(!t.shape)throw new Error("Reshape operation requires shape parameter");return this._executePythonOp("cpu_ops.reshape",e,t)},sum:async(e,t)=>this._executePythonOp("cpu_ops.sum",e,t),mean:async(e,t)=>this._executePythonOp("cpu_ops.mean",e,t),max:async(e,t)=>this._executePythonOp("cpu_ops.max",e,t),min:async(e,t)=>this._executePythonOp("cpu_ops.min",e,t),relu:async(e,t)=>this._executePythonOp("cpu_ops.relu",e,t),sigmoid:async(e,t)=>this._executePythonOp("cpu_ops.sigmoid",e,t),tanh:async(e,t)=>this._executePythonOp("cpu_ops.tanh",e,t),softmax:async(e,t)=>this._executePythonOp("cpu_ops.softmax",e,t),exp:async(e,t)=>this._executePythonOp("cpu_ops.exp",e,t),log:async(e,t)=>this._executePythonOp("cpu_ops.log",e,t),sqrt:async(e,t)=>this._executePythonOp("cpu_ops.sqrt",e,t),power:async(e,t)=>this._executePythonOp("cpu_ops.power",e,t),abs:async(e,t)=>this._executePythonOp("cpu_ops.abs",e,t),sign:async(e,t)=>this._executePythonOp("cpu_ops.sign",e,t),clip:async(e,t)=>{if(void 0===t.min||void 0===t.max)throw new Error("Clip operation requires min and max parameters");return this._executePythonOp("cpu_ops.clip",e,t)}}}async _executePythonOp(e,t,r){if(!this.runtime)throw new Error("Runtime not available for CPU operations");try{const i=[],n=Array.isArray(t)?t:[t];for(let e=0;e<n.length;e++){const t=`tensor_${e}`;this.runtime.setGlobal(t,n[e]),i.push(t)}let a=`${e}(${i.join(", ")})`;if(r){const t=[];for(const[e,i]of Object.entries(r))"axes"===e?t.push(`${e}=${i}`):"string"==typeof i?t.push(`${e}="${i}"`):Array.isArray(i)?t.push(`${e}=${JSON.stringify(i)}`):t.push(`${e}=${i}`);t.length>0&&(a=`${e}(${i.join(", ")}, ${t.join(", ")})`)}const s=`\nresult = ${a}\nresult.tolist() if hasattr(result, 'tolist') else result\n`,o=await this.runtime.runPython(s,{captureOutput:!0,timeout:r.timeout||1e4});for(const e of i)await this.runtime.runPython(`del ${e}`,{captureOutput:!1});return o}catch(e){throw new Error(`CPU operation failed: ${e.message}`)}}_updateStats(e){this.stats.operations++,this.stats.totalExecutionTime+=e,this.stats.averageExecutionTime=this.stats.totalExecutionTime/this.stats.operations,this.stats.lastOperationTime=e}_getResultSize(e){return Array.isArray(e)||ArrayBuffer.isView(e)?e.length:e instanceof ArrayBuffer?e.byteLength/4:1}}class g{constructor(e){this.max=e,this.current=0,this.queue=[]}async acquire(){return new Promise(e=>{this.current<this.max?(this.current++,e()):this.queue.push(e)})}release(){if(this.current--,this.queue.length>0){const e=this.queue.shift();this.current++,e()}}}const m=h;class _ extends i.A{constructor(e={}){super(),this.config={maxWorkers:e.maxWorkers||navigator.hardwareConcurrency||4,workerTimeout:e.workerTimeout||3e4,enableLoadBalancing:!1!==e.enableLoadBalancing,queueMaxSize:e.queueMaxSize||100,...e},this.isInitialized=!1,this.workers=[],this.availableWorkers=[],this.busyWorkers=new Map,this.taskQueue=[],this.stats={workers:0,operations:0,totalExecutionTime:0,averageExecutionTime:0,queuedOperations:0,failedOperations:0,workerRestarts:0},this.nextTaskId=1,this.pendingTasks=new Map}async initialize(){if(this.isInitialized)return!0;try{return this.emit("init:start",{maxWorkers:this.config.maxWorkers}),await this._createWorkerPool(),this._startTaskProcessor(),this.isInitialized=!0,this.emit("init:complete",{workers:this.workers.length,ready:this.availableWorkers.length}),!0}catch(e){throw this.emit("init:error",{error:e}),e}}async execute(e,t,r={}){if(!this.isInitialized)throw new Error("Worker engine not initialized");return new Promise((i,n)=>{const a=this.nextTaskId++,s=performance.now(),o={id:a,operation:e,tensors:t,options:r,startTime:s,resolve:i,reject:n,timeout:setTimeout(()=>{this._handleTaskTimeout(a)},r.timeout||this.config.workerTimeout)};this.pendingTasks.set(a,o),this._queueTask(o),this.emit("task:queued",{taskId:a,operation:e,queueSize:this.taskQueue.length})})}async executeBatch(e,t={}){const{parallel:r=!0,maxConcurrency:i=this.config.maxWorkers,loadBalance:n=this.config.enableLoadBalancing}=t;if(!r){const t=[];for(const r of e){const e=await this.execute(r.operation,r.tensors,r.options);t.push(e)}return t}if(n){const t=this._distributeOperations(e).map(e=>this.execute(e.operation,e.tensors,e.options));return Promise.all(t)}const a=new f(i),s=e.map(async e=>{await a.acquire();try{return await this.execute(e.operation,e.tensors,e.options)}finally{a.release()}});return Promise.all(s)}getStats(){return{...this.stats,isInitialized:this.isInitialized,availableWorkers:this.availableWorkers.length,busyWorkers:this.busyWorkers.size,queuedTasks:this.taskQueue.length,pendingTasks:this.pendingTasks.size,type:"worker"}}async cleanup(){try{this.emit("cleanup:start");for(const[e,t]of this.pendingTasks.entries())clearTimeout(t.timeout),t.reject(new Error("Worker engine shutting down"));this.pendingTasks.clear(),this.taskQueue=[];for(const e of this.workers)e.terminate();this.workers=[],this.availableWorkers=[],this.busyWorkers.clear(),this.isInitialized=!1,this.emit("cleanup:complete")}catch(e){throw this.emit("cleanup:error",{error:e}),e}}async _createWorkerPool(){const e=this._generateWorkerScript(),t=new Blob([e],{type:"application/javascript"}),r=URL.createObjectURL(t);try{for(let e=0;e<this.config.maxWorkers;e++){const t=new Worker(r),i=e;t.addEventListener("message",e=>{this._handleWorkerMessage(i,e)}),t.addEventListener("error",e=>{this._handleWorkerError(i,e)}),t.addEventListener("messageerror",e=>{this._handleWorkerError(i,e)}),this.workers.push(t),this.availableWorkers.push(i),this.stats.workers++,this.emit("worker:created",{workerId:i})}}finally{URL.revokeObjectURL(r)}}_generateWorkerScript(){return"\n// Worker script for tensor operations\nclass WorkerTensorOps {\n  constructor() {\n    this.operations = {\n      add: (a, b) => a.map((val, i) => val + b[i]),\n      subtract: (a, b) => a.map((val, i) => val - b[i]),\n      multiply: (a, b) => a.map((val, i) => val * b[i]),\n      divide: (a, b) => a.map((val, i) => val / (b[i] || 1e-12)),\n      \n      matmul: (a, b, shapeA, shapeB) => {\n        if (shapeA.length !== 2 || shapeB.length !== 2) {\n          throw new Error('Matrix multiplication requires 2D arrays');\n        }\n        \n        const [rowsA, colsA] = shapeA;\n        const [rowsB, colsB] = shapeB;\n        \n        if (colsA !== rowsB) {\n          throw new Error('Matrix dimensions incompatible for multiplication');\n        }\n        \n        const result = new Array(rowsA * colsB).fill(0);\n        \n        for (let i = 0; i < rowsA; i++) {\n          for (let j = 0; j < colsB; j++) {\n            let sum = 0;\n            for (let k = 0; k < colsA; k++) {\n              sum += a[i * colsA + k] * b[k * colsB + j];\n            }\n            result[i * colsB + j] = sum;\n          }\n        }\n        \n        return result;\n      },\n      \n      transpose: (a, shape) => {\n        if (shape.length !== 2) {\n          throw new Error('Transpose currently supports only 2D arrays');\n        }\n        \n        const [rows, cols] = shape;\n        const result = new Array(rows * cols);\n        \n        for (let i = 0; i < rows; i++) {\n          for (let j = 0; j < cols; j++) {\n            result[j * rows + i] = a[i * cols + j];\n          }\n        }\n        \n        return result;\n      },\n      \n      sum: (a, axis) => {\n        if (axis === null || axis === undefined) {\n          return a.reduce((sum, val) => sum + val, 0);\n        }\n        // Simplified sum along axis (would need full tensor implementation)\n        return a.reduce((sum, val) => sum + val, 0);\n      },\n      \n      mean: (a, axis) => {\n        const sum = this.operations.sum(a, axis);\n        return Array.isArray(sum) ? sum.map(val => val / a.length) : sum / a.length;\n      },\n      \n      relu: (a) => a.map(val => Math.max(0, val)),\n      \n      sigmoid: (a) => a.map(val => 1 / (1 + Math.exp(-Math.max(-250, Math.min(250, val))))),\n      \n      tanh: (a) => a.map(val => Math.tanh(val)),\n      \n      softmax: (a) => {\n        const maxVal = Math.max(...a);\n        const exp = a.map(val => Math.exp(val - maxVal));\n        const sum = exp.reduce((s, val) => s + val, 0);\n        return exp.map(val => val / sum);\n      },\n      \n      exp: (a) => a.map(val => Math.exp(Math.max(-250, Math.min(250, val)))),\n      \n      log: (a) => a.map(val => Math.log(Math.max(1e-12, val))),\n      \n      sqrt: (a) => a.map(val => Math.sqrt(Math.max(0, val))),\n      \n      abs: (a) => a.map(val => Math.abs(val)),\n      \n      power: (a, b) => {\n        if (Array.isArray(b)) {\n          return a.map((val, i) => Math.pow(val, b[i]));\n        } else {\n          return a.map(val => Math.pow(val, b));\n        }\n      }\n    };\n  }\n  \n  execute(operation, tensors, options = {}) {\n    try {\n      const op = this.operations[operation];\n      if (!op) {\n        throw new Error(`Unsupported operation: ${operation}`);\n      }\n      \n      // Convert tensors to arrays if needed\n      const tensorArrays = tensors.map(tensor => {\n        if (tensor.data && tensor.shape) {\n          return { data: Array.from(tensor.data), shape: tensor.shape };\n        } else if (Array.isArray(tensor)) {\n          return { data: tensor, shape: [tensor.length] };\n        } else {\n          return { data: Array.from(tensor), shape: [tensor.length] };\n        }\n      });\n      \n      // Execute operation\n      let result;\n      switch (operation) {\n        case 'matmul':\n          result = op(tensorArrays[0].data, tensorArrays[1].data, \n                      tensorArrays[0].shape, tensorArrays[1].shape);\n          break;\n        case 'transpose':\n          result = op(tensorArrays[0].data, tensorArrays[0].shape);\n          break;\n        case 'power':\n          if (tensorArrays.length > 1) {\n            result = op(tensorArrays[0].data, tensorArrays[1].data);\n          } else {\n            result = op(tensorArrays[0].data, options.exponent || 2);\n          }\n          break;\n        default:\n          if (tensorArrays.length === 1) {\n            result = op(tensorArrays[0].data, options.axis);\n          } else {\n            result = op(tensorArrays[0].data, tensorArrays[1].data);\n          }\n      }\n      \n      return result;\n    } catch (error) {\n      throw new Error(`Worker operation failed: ${error.message}`);\n    }\n  }\n}\n\nconst tensorOps = new WorkerTensorOps();\n\nself.addEventListener('message', function(event) {\n  const { taskId, operation, tensors, options } = event.data;\n  \n  try {\n    const startTime = performance.now();\n    const result = tensorOps.execute(operation, tensors, options);\n    const executionTime = performance.now() - startTime;\n    \n    self.postMessage({\n      taskId,\n      success: true,\n      result,\n      executionTime\n    });\n  } catch (error) {\n    self.postMessage({\n      taskId,\n      success: false,\n      error: error.message\n    });\n  }\n});\n"}_queueTask(e){if(this.taskQueue.length>=this.config.queueMaxSize)return e.reject(new Error("Worker queue full")),void this.stats.failedOperations++;this.taskQueue.push(e),this.stats.queuedOperations++,this._processTaskQueue()}_startTaskProcessor(){setInterval(()=>{this._processTaskQueue()},10)}_processTaskQueue(){for(;this.taskQueue.length>0&&this.availableWorkers.length>0;){const e=this.taskQueue.shift(),t=this.availableWorkers.shift();this.busyWorkers.set(t,e),this.workers[t].postMessage({taskId:e.id,operation:e.operation,tensors:e.tensors,options:e.options}),this.emit("task:started",{taskId:e.id,workerId:t,operation:e.operation})}}_handleWorkerMessage(e,t){const{taskId:r,success:i,result:n,error:a,executionTime:s}=t.data,o=this.pendingTasks.get(r);if(!o)return void p.A.warn("Received message for unknown task:",{taskId:r,workerId:e,availableTasks:Array.from(this.pendingTasks.keys())});clearTimeout(o.timeout),this.pendingTasks.delete(r),this.busyWorkers.delete(e),this.availableWorkers.push(e);const u=performance.now()-o.startTime;this.stats.operations++,this.stats.totalExecutionTime+=u,this.stats.averageExecutionTime=this.stats.totalExecutionTime/this.stats.operations,i?(o.resolve(n),this.emit("task:completed",{taskId:r,workerId:e,executionTime:u,workerTime:s})):(this.stats.failedOperations++,o.reject(new Error(a)),this.emit("task:failed",{taskId:r,workerId:e,error:a,executionTime:u}))}_handleWorkerError(e,t){this.emit("worker:error",{workerId:e,error:t});const r=this.busyWorkers.get(e);r&&(clearTimeout(r.timeout),this.pendingTasks.delete(r.id),this.busyWorkers.delete(e),r.reject(new Error(`Worker error: ${t.message||t}`)),this.stats.failedOperations++),this._restartWorker(e)}_handleTaskTimeout(e){const t=this.pendingTasks.get(e);if(t){this.pendingTasks.delete(e);for(const[t,r]of this.busyWorkers.entries())if(r.id===e){this.busyWorkers.delete(t),this._restartWorker(t);break}this.stats.failedOperations++,t.reject(new Error(`Task timeout after ${this.config.workerTimeout}ms`)),this.emit("task:timeout",{taskId:e,timeout:this.config.workerTimeout})}}async _restartWorker(e){try{this.workers[e]?.terminate();const t=this._generateWorkerScript(),r=new Blob([t],{type:"application/javascript"}),i=URL.createObjectURL(r),n=new Worker(i);URL.revokeObjectURL(i),n.addEventListener("message",t=>{this._handleWorkerMessage(e,t)}),n.addEventListener("error",t=>{this._handleWorkerError(e,t)}),this.workers[e]=n,this.availableWorkers.push(e),this.stats.workerRestarts++,this.emit("worker:restarted",{workerId:e})}catch(t){this.emit("worker:restart-failed",{workerId:e,error:t})}}_distributeOperations(e){return e.map((e,t)=>({...e,preferredWorker:t%this.config.maxWorkers}))}}class f{constructor(e){this.max=e,this.current=0,this.queue=[]}async acquire(){return new Promise(e=>{this.current<this.max?(this.current++,e()):this.queue.push(e)})}release(){if(this.current--,this.queue.length>0){const e=this.queue.shift();this.current++,e()}}}const y=_;class b extends i.A{constructor(e={}){super(),this.config={webgpuMinElements:e.webgpuMinElements||1e3,workerMinElements:e.workerMinElements||1e4,maxConcurrentOperations:e.maxConcurrentOperations||4,memoryThresholdMB:e.memoryThresholdMB||512,enableAutoFallback:!1!==e.enableAutoFallback,fallbackTimeout:e.fallbackTimeout||5e3,enableAdaptiveSelection:!1!==e.enableAdaptiveSelection,performanceHistorySize:e.performanceHistorySize||100,...e},this.webgpu=new c(e.webgpu||{}),this.cpu=new m(e.cpu||{}),this.worker=new y(e.worker||{}),this.isInitialized=!1,this.availableStrategies=new Set,this.currentOperations=new Map,this.performanceHistory=new Map,this.strategyPreferences=new Map,this.resourceMonitor={memoryUsage:0,activeOperations:0,gpuUtilization:0}}async initialize(){if(this.isInitialized)return this.availableStrategies;this.emit("init:start");try{try{if(await this.webgpu.initialize())this.availableStrategies.add("webgpu"),this._setupEngineForwarding(this.webgpu,"webgpu"),this.emit("init:webgpu-success",{message:"WebGPU engine initialized successfully"});else{const e=this.webgpu.initFailureReason||"Unknown WebGPU initialization failure";this.emit("init:webgpu-failed",{error:new Error(e),details:"WebGPU engine initialization returned false"})}}catch(e){this.emit("init:webgpu-failed",{error:e})}await this.cpu.initialize(),this.availableStrategies.add("cpu"),this._setupEngineForwarding(this.cpu,"cpu");try{await this.worker.initialize(),this.availableStrategies.add("worker"),this._setupEngineForwarding(this.worker,"worker")}catch(e){this.emit("init:worker-failed",{error:e})}return this.isInitialized=!0,this.emit("init:complete",{strategies:Array.from(this.availableStrategies)}),this.availableStrategies}catch(e){throw this.emit("init:error",{error:e}),e}}async execute(e,t,r={}){if(!this.isInitialized)throw new Error("ComputeStrategy not initialized. Call initialize() first.");const i=performance.now(),n=this._generateOperationId();this.emit("execute:start",{operation:e,operationId:n,options:r});try{const a=await this._selectStrategy(e,t,r);this.currentOperations.set(n,{operation:e,strategy:a.name,startTime:i,tensors:Array.isArray(t)?t.length:1}),this.resourceMonitor.activeOperations++;const s=await this._executeWithFallback(a,e,t,r),o=performance.now()-i;return this._recordPerformance(e,a.name,o,t),this.currentOperations.delete(n),this.resourceMonitor.activeOperations--,this.emit("execute:complete",{operation:e,operationId:n,strategy:a.name,executionTime:o,resultSize:s.length}),s}catch(t){throw this.currentOperations.delete(n),this.resourceMonitor.activeOperations--,this.emit("execute:error",{operation:e,operationId:n,error:t}),t}}async executeBatch(e,t={}){const{parallel:r=!0,maxConcurrency:i=this.config.maxConcurrentOperations,loadBalance:n=!0}=t;if(!r){const t=[];for(const r of e){const e=await this.execute(r.operation,r.tensors,r.options);t.push(e)}return t}if(n)return this._executeWithLoadBalancing(e,i);const a=new x(i),s=e.map(async e=>{await a.acquire();try{return await this.execute(e.operation,e.tensors,e.options)}finally{a.release()}});return Promise.all(s)}getStats(){const e={availableStrategies:Array.from(this.availableStrategies),activeOperations:this.resourceMonitor.activeOperations,resourceMonitor:{...this.resourceMonitor},strategyPreferences:Object.fromEntries(this.strategyPreferences),engines:{}};return this.availableStrategies.has("webgpu")&&(e.engines.webgpu=this.webgpu.getStats()),this.availableStrategies.has("cpu")&&(e.engines.cpu=this.cpu.getStats()),this.availableStrategies.has("worker")&&(e.engines.worker=this.worker.getStats()),e}setStrategyPreference(e,t){if(!this.availableStrategies.has(t))throw new Error(`Strategy '${t}' not available`);this.strategyPreferences.set(e,t),this.emit("strategy:preference-set",{operation:e,strategy:t})}resetAdaptiveSelection(){this.performanceHistory.clear(),this.strategyPreferences.clear(),this.emit("strategy:reset")}async cleanup(){this.emit("cleanup:start");try{const e=[];this.webgpu&&e.push(this.webgpu.cleanup()),this.cpu&&e.push(this.cpu.cleanup()),this.worker&&e.push(this.worker.cleanup()),await Promise.all(e),this.availableStrategies.clear(),this.currentOperations.clear(),this.performanceHistory.clear(),this.isInitialized=!1,this.emit("cleanup:complete")}catch(e){throw this.emit("cleanup:error",{error:e}),e}}async _selectStrategy(e,t,r){if(r.strategy&&this.availableStrategies.has(r.strategy))return this._getEngine(r.strategy);if(this.config.enableAdaptiveSelection&&this.strategyPreferences.has(e)){const t=this.strategyPreferences.get(e);if(this.availableStrategies.has(t))return this._getEngine(t)}const i=this._calculateWorkloadSize(t),n=this._estimateComplexity(e,t),a=this._assessResourcePressure();return this._shouldUseWebGPU(e,i,n,a)?this._getEngine("webgpu"):this._shouldUseWorker(e,i,n,a)?this._getEngine("worker"):this._getEngine("cpu")}_shouldUseWebGPU(e,t,r,i){return!!this.availableStrategies.has("webgpu")&&(!(t<this.config.webgpuMinElements)&&(!(i.memory>.8||i.activeOperations>.9)&&(!!["matmul","conv2d","add","multiply","relu","sigmoid"].includes(e)||r>.7)))}_shouldUseWorker(e,t,r,i){return!!this.availableStrategies.has("worker")&&(t>this.config.workerMinElements&&r>.5||i.activeOperations>.7)}async _executeWithFallback(e,t,r,i){if(!this.config.enableAutoFallback)return e.execute(t,r,i);try{const n=e.execute(t,r,i),a=new Promise((e,t)=>{setTimeout(()=>t(new Error("Operation timeout")),this.config.fallbackTimeout)});return await Promise.race([n,a])}catch(n){this.emit("fallback:triggered",{from:e.name,operation:t,error:n.message});const a=this._getFallbackOrder(e.name);for(const e of a)if(this.availableStrategies.has(e))try{const n=this._getEngine(e);return this.emit("fallback:executing",{strategy:e,operation:t}),await n.execute(t,r,i)}catch(r){this.emit("fallback:failed",{strategy:e,operation:t,error:r.message})}throw n}}async _executeWithLoadBalancing(e,t){const r=this._groupOperationsByLoad(e),i=this._distributeOperations(r),n=new x(t),a=i.map(async e=>{await n.acquire();try{return await this.execute(e.operation,e.tensors,e.options)}finally{n.release()}});return Promise.all(a)}_getEngine(e){const t={webgpu:this.webgpu,cpu:this.cpu,worker:this.worker}[e];if(!t)throw new Error(`Engine '${e}' not found`);return t.name=e,t}_calculateWorkloadSize(e){return(Array.isArray(e)?e:[e]).reduce((e,t)=>ArrayBuffer.isView(t)?e+t.length:t instanceof ArrayBuffer?e+t.byteLength/4:e,0)}_estimateComplexity(e,t){const r={add:.1,multiply:.1,matmul:.8,conv2d:.9,relu:.2,sigmoid:.3,softmax:.6,transpose:.3}[e]||.5,i=this._calculateWorkloadSize(t),n=Math.log10(Math.max(i,1))/6;return Math.min(r*(1+n),1)}_assessResourcePressure(){return{memory:this.resourceMonitor.memoryUsage/(1024*this.config.memoryThresholdMB*1024),activeOperations:this.resourceMonitor.activeOperations/this.config.maxConcurrentOperations,gpu:this.resourceMonitor.gpuUtilization}}_recordPerformance(e,t,r,i){if(!this.config.enableAdaptiveSelection)return;this.performanceHistory.has(e)||this.performanceHistory.set(e,{webgpu:[],cpu:[],worker:[]});const n=this.performanceHistory.get(e)[t];n.length>=this.config.performanceHistorySize&&n.shift(),n.push({executionTime:r,workloadSize:this._calculateWorkloadSize(i),timestamp:Date.now()}),this._updateStrategyPreference(e)}_updateStrategyPreference(e){const t=this.performanceHistory.get(e);if(!t)return;const r={};for(const[e,i]of Object.entries(t))if(i.length>0){const t=i.reduce((e,t)=>e+t.executionTime,0)/i.length;r[e]=t}const i=Object.entries(r).reduce((e,[t,r])=>!e||r<e.avgTime?{strategy:t,avgTime:r}:e,null);i&&this.availableStrategies.has(i.strategy)&&this.strategyPreferences.set(e,i.strategy)}_getFallbackOrder(e){return{webgpu:["cpu","worker"],worker:["cpu"],cpu:[]}[e]||[]}_generateOperationId(){return`op_${Date.now()}_${Math.random().toString(36).substr(2,9)}`}_setupEngineForwarding(e,t){e.on("init:complete",e=>this.emit(`${t}:ready`,e)),e.on("compute:error",e=>this.emit(`${t}:error`,e)),e.on("cleanup:complete",()=>this.emit(`${t}:cleanup`))}_groupOperationsByLoad(e){return e.map(e=>({...e,estimatedLoad:this._estimateComplexity(e.operation,e.tensors),workloadSize:this._calculateWorkloadSize(e.tensors)}))}_distributeOperations(e){return e}}class x{constructor(e){this.max=e,this.current=0,this.queue=[]}async acquire(){return new Promise(e=>{this.current<this.max?(this.current++,e()):this.queue.push(e)})}release(){if(this.current--,this.queue.length>0){const e=this.queue.shift();this.current++,e()}}}const w=b},847:(e,t,r)=>{r.d(t,{O:()=>n});var i=r(626);class n{constructor(e,t={}){if(this.device=t.device||"webgpu",this.dtype=t.dtype||"float32",this.requires_grad=t.requires_grad||!1,this.grad=null,this.grad_fn=null,Array.isArray(e)||ArrayBuffer.isView(e))this.data=this._processInputData(e),this.shape=t.shape||this._inferShape(e);else if(e instanceof ArrayBuffer)this.data=new Float32Array(e),this.shape=t.shape||[this.data.length];else if(e&&"object"==typeof e&&void 0!==e.length)try{const r=Array.from(e);this.data=this._processInputData(r),this.shape=t.shape||this._inferShape(r)}catch(t){throw new Error(`Invalid tensor data: cannot convert to array. Got ${typeof e}, error: ${t.message}`)}else{if("number"!=typeof e)throw new Error(`Invalid tensor data type. Expected Array, TypedArray, ArrayBuffer, array-like object, or number. Got: ${typeof e} (${e})`);this.data=new Float32Array([e]),this.shape=t.shape||[1]}this.ndim=this.shape.length,this.size=this.shape.reduce((e,t)=>e*t,1),this.computeEngine=t.computeEngine||null,this._buffer=null,this._isOnGPU=!1}static setComputeEngine(e){n.globalComputeEngine=e}get _engine(){return this.computeEngine||n.globalComputeEngine}async _executeGPUOperation(e,t=null,r={}){if(!this._engine)throw new Error("WebGPU compute engine not available");const a=t?[this.data,t.data||t]:[this.data];try{const i=await this._engine.execute(e,a,{shape:this.shape,otherShape:t?.shape,dtype:this.dtype,...r}),s=this._calculateResultShape(e,t,r);return new n(i,{shape:s,device:this.device,dtype:this.dtype,computeEngine:this._engine,requires_grad:this.requires_grad||t?.requires_grad})}catch(n){return i.A.warn(`WebGPU operation ${e} failed, falling back to CPU:`,{operation:e,error:n.message,tensorShape:this.shape,otherShape:t?.shape,fallbackReason:"gpu-operation-failed"}),this._executeCPUFallback(e,t,r)}}_executeCPUFallback(e,t,r){const i=this._cpuOperations[e]?.(this.data,t?.data||t,r);if(!i)throw new Error(`Operation ${e} not supported`);const a=this._calculateResultShape(e,t,r);return new n(i,{shape:a,device:"cpu",dtype:this.dtype,requires_grad:this.requires_grad||t?.requires_grad})}async add(e){return this._executeGPUOperation("add",e)}async sub(e){return this._executeGPUOperation("sub",e)}async mul(e){return this._executeGPUOperation("mul",e)}async div(e){return this._executeGPUOperation("div",e)}async pow(e){return this._executeGPUOperation("pow",e)}async matmul(e){if(2!==this.ndim||2!==e.ndim)throw new Error("matmul requires 2D tensors");if(this.shape[1]!==e.shape[0])throw new Error(`Cannot multiply matrices of shapes ${this.shape} and ${e.shape}`);return this._executeGPUOperation("matmul",e)}async bmm(e){if(3!==this.ndim||3!==e.ndim)throw new Error("bmm requires 3D tensors");return this._executeGPUOperation("bmm",e)}async transpose(e=0,t=1){return this._executeGPUOperation("transpose",null,{dim0:e,dim1:t})}async relu(){return this._executeGPUOperation("relu")}async leaky_relu(e=.01){return this._executeGPUOperation("leaky_relu",null,{negativeSlope:e})}async sigmoid(){return this._executeGPUOperation("sigmoid")}async tanh(){return this._executeGPUOperation("tanh")}async gelu(){return this._executeGPUOperation("gelu")}async softmax(e=-1){return this._executeGPUOperation("softmax",null,{dim:e})}async sum(e=null,t=!1){return this._executeGPUOperation("sum",null,{dim:e,keepDim:t})}async mean(e=null,t=!1){return this._executeGPUOperation("mean",null,{dim:e,keepDim:t})}async max(e=null,t=!1){return null===e?await this._executeGPUOperation("max_reduce"):this._executeGPUOperation("max",null,{dim:e,keepDim:t})}async min(e=null,t=!1){return null===e?await this._executeGPUOperation("min_reduce"):this._executeGPUOperation("min",null,{dim:e,keepDim:t})}async std(e=null,t=!1,r=!0){return this._executeGPUOperation("std",null,{dim:e,keepDim:t,unbiased:r})}async var(e=null,t=!1,r=!0){return this._executeGPUOperation("var",null,{dim:e,keepDim:t,unbiased:r})}async exp(){return this._executeGPUOperation("exp")}async log(){return this._executeGPUOperation("log")}async sqrt(){return this._executeGPUOperation("sqrt")}async abs(){return this._executeGPUOperation("abs")}view(...e){if(e.reduce((e,t)=>e*t,1)!==this.size)throw new Error(`Cannot reshape tensor of size ${this.size} to shape ${e}`);return new n(this.data,{shape:e,device:this.device,dtype:this.dtype,computeEngine:this._engine,requires_grad:this.requires_grad})}reshape(...e){return this.view(...e)}unsqueeze(e){const t=[...this.shape];return e<0&&(e=t.length+e+1),t.splice(e,0,1),this.view(...t)}squeeze(e=null){let t;if(null===e)t=this.shape.filter(e=>1!==e);else{if(1!==this.shape[e])throw new Error(`Cannot squeeze dimension ${e} of size ${this.shape[e]}`);t=[...this.shape],t.splice(e,1)}return this.view(...t)}flatten(e=0,t=-1){-1===t&&(t=this.ndim-1);const r=this.shape.slice(0,e),i=this.shape.slice(e,t+1),n=this.shape.slice(t+1),a=[...r,i.reduce((e,t)=>e*t,1),...n];return this.view(...a)}to(e){return e===this.device?this:new n(this.data.slice(),{shape:this.shape,device:e,dtype:this.dtype,computeEngine:this._engine,requires_grad:this.requires_grad})}cpu(){return this.to("cpu")}cuda(){return this.to("webgpu")}retain_grad(){if(!this.requires_grad)throw new Error("can't retain_grad on Tensor that has requires_grad=False");return this._retain_grad=!0,this}backward(e=null,t=!1,r=!1){if(!this.requires_grad)return;if(null===e){if(1!==this.size)throw new Error("grad can be implicitly created only for scalar outputs");e=new n([1],{shape:this.shape})}null===this.grad&&(this.grad=new n(new Float32Array(this.size).fill(0),{shape:this.shape,device:this.device,dtype:this.dtype}));const i=e.data||e;for(let e=0;e<this.grad.data.length;e++)this.grad.data[e]+=Array.isArray(i)?i[e]:i;this.grad_fn&&this.grad_fn(e)}numpy(){return this.data}tolist(){return 1===this.ndim?Array.from(this.data):this._arrayToNestedList(this.data,this.shape)}item(){if(1!==this.size)throw new Error("item() can only be called on tensors with one element");return this.data[0]}clone(){return new n(this.data.slice(),{shape:this.shape,device:this.device,dtype:this.dtype,computeEngine:this._engine,requires_grad:this.requires_grad})}detach(){const e=this.clone();return e.requires_grad=!1,e.grad_fn=null,e}_processInputData(e){if(Array.isArray(e))return new Float32Array(this._flattenArray(e));if(ArrayBuffer.isView(e))return new Float32Array(e);throw new Error("Unsupported data type")}_flattenArray(e){const t=[],r=e=>{Array.isArray(e)?e.forEach(r):t.push(Number(e))};return r(e),t}_inferShape(e){if(!Array.isArray(e))return[e.length||1];const t=e=>{if(!Array.isArray(e))return[];const r=[e.length];return e.length>0&&Array.isArray(e[0])&&r.push(...t(e[0])),r};return t(e)}_calculateResultShape(e,t,r){switch(e){case"matmul":return[this.shape[0],t.shape[1]];case"bmm":return[this.shape[0],this.shape[1],t.shape[2]];case"transpose":const e=[...this.shape],{dim0:i=0,dim1:n=1}=r;return[e[i],e[n]]=[e[n],e[i]],e;case"sum":case"mean":if(null===r.dim)return r.keepDim?this.shape:[1];{const e=[...this.shape];return r.keepDim?e[r.dim]=1:e.splice(r.dim,1),0===e.length?[1]:e}default:return this.shape}}_arrayToNestedList(e,t){if(1===t.length)return Array.from(e);const r=[],i=t.slice(1).reduce((e,t)=>e*t,1);for(let n=0;n<t[0];n++){const a=n*i,s=a+i,o=e.slice(a,s);r.push(this._arrayToNestedList(o,t.slice(1)))}return r}get _cpuOperations(){return{add:(e,t)=>e.map((e,r)=>e+(Array.isArray(t)?t[r]:t)),sub:(e,t)=>e.map((e,r)=>e-(Array.isArray(t)?t[r]:t)),mul:(e,t)=>e.map((e,r)=>e*(Array.isArray(t)?t[r]:t)),div:(e,t)=>e.map((e,r)=>e/(Array.isArray(t)?t[r]:t)),pow:(e,t)=>e.map((e,r)=>Math.pow(e,Array.isArray(t)?t[r]:t)),exp:e=>e.map(e=>Math.exp(e)),log:e=>e.map(e=>Math.log(e)),sqrt:e=>e.map(e=>Math.sqrt(e)),abs:e=>e.map(e=>Math.abs(e)),relu:e=>e.map(e=>Math.max(0,e)),sigmoid:e=>e.map(e=>1/(1+Math.exp(-e))),tanh:e=>e.map(e=>Math.tanh(e)),std:(e,t={})=>{const r=e.reduce((e,t)=>e+t,0)/e.length,i=e.reduce((e,t)=>e+Math.pow(t-r,2),0)/(t.unbiased?e.length-1:e.length);return[Math.sqrt(i)]},var:(e,t={})=>{const r=e.reduce((e,t)=>e+t,0)/e.length;return[e.reduce((e,t)=>e+Math.pow(t-r,2),0)/(t.unbiased?e.length-1:e.length)]}}}toString(){return`WebGPUTensor(${this.shape.join("x")}, device=${this.device}, dtype=${this.dtype})`}[Symbol.toPrimitive](e){return"number"===e&&1===this.size?this.data[0]:this.toString()}"@"(e){return this.matmul(e)}__add__(e){return this.add(e)}__sub__(e){return this.sub(e)}__mul__(e){return this.mul(e)}__truediv__(e){return this.div(e)}__matmul__(e){return this.matmul(e)}}}}]);